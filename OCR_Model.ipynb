{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9623eba1-51f0-4247-bcf8-01c48300a0ac",
   "metadata": {},
   "source": [
    "# Adaptation of a Project By Datacamp\n",
    "### Solution Proposal by: AndrÃ© Fernandes\n",
    "### Found me on:\n",
    "#### -> https://github.com/vBarFace \n",
    "#### -> https://www.linkedin.com/in/andr%C3%A9-fernandes-868006207/\n",
    "\n",
    "# ------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f519e703-93f7-48d2-a83d-e69ea510130f",
   "metadata": {},
   "source": [
    "## Exercise introduction by Datacamp: \n",
    "\n",
    "###### DigiNsure Inc. is an innovative insurance company focused on enhancing the efficiency of processing claims and customer service interactions. Their newest initiative is digitizing all historical insurance claim documents, which includes improving the labeling of some IDs scanned from paper documents and identifying them as primary or secondary IDs.\n",
    "\n",
    "###### To help them in their effort, you'll be using multi-modal learning to train an Optical Character Recognition (OCR) model. To improve the classification, the model will use images of the scanned documents as input and their insurance type (home, life, auto, health, or other). Integrating different data modalities (such as image and text) enables the model to perform better in complex scenarios, helping to capture more nuanced information. The labels that the model will be trained to identify are of two types: a primary and a secondary ID, for each image-insurance type pair.\n",
    "\n",
    "# ------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12148d21-bc3e-45f7-b8c7-d2c8985feab9",
   "metadata": {},
   "source": [
    "## Project Instructions:\n",
    "\n",
    "##### Develop an Optical Character Recognition (OCR) model to sort categories of ID codes extracted from scanned insurance documents.\n",
    "##### - Create a model named OCRModel in PyTorch. It should have the following specifications:\n",
    "######   - A network architecture with different layers to ingest both the image and the type. The layers relative to the image should be saved as a sequential module called image_layer, and compatible the input dimensions of the images (64x64 pixels size).\n",
    "######  - A Conv2d layer with kernel size 3x3, padding 1, and appropriate in/out channels.\n",
    "##### - Train the Model: call the model as model and use an appropriate optimizer and loss function to train it. Iterate through your training for ten epochs.l.\n",
    "\n",
    "# ------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a973db5-51e0-401f-9e46-032ff8a5b278",
   "metadata": {},
   "source": [
    "### Given code by Datacamp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71cf45de-2f09-41b4-bfac-e1ff7203eb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchvisio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33d77ae5-8e3a-4e96-a26e-c155a7ba357d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "#import matplotlib.pyplot as plt\n",
    "#import numpy as np\n",
    "#from project_utils import ProjectDataset\n",
    "#import pickle \n",
    "#import torch\n",
    "#import torch.nn as nn\n",
    "#from torch.utils.data import DataLoader\n",
    "\n",
    "# Load the data\n",
    "#dataset = pickle.load(open('ocr_insurance_dataset.pkl', 'rb'))\n",
    "\n",
    "# Define a function to visualize codes with their corresponding types and labels \n",
    "#def show_dataset_images(dataset, num_images=5):\n",
    "    #fig, axes = plt.subplots(1, min(num_images, len(dataset)), figsize=(20, 4))\n",
    "    #for ax, idx in zip(axes, np.random.choice(len(dataset), min(num_images, len(dataset)), False)):\n",
    "        #img, lbl = dataset[idx]\n",
    "        #ax.imshow((img[0].numpy() * 255).astype(np.uint8).reshape(64,64), cmap='gray'), ax.axis('off')\n",
    "        #ax.set_title(f\"Type: {list(dataset.type_mapping.keys())[img[1].tolist().index(1)]}\\nLabel: {list(dataset.label_mapping.keys())[list(dataset.label_mapping.values()).index(lbl)]}\")\n",
    "    #plt.show()\n",
    "\n",
    "# Inspect 5 codes images from the dataset\n",
    "#show_dataset_images(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a63f7ea8-d06c-4e20-91ff-fa3274cfe9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start coding here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d506c0e1-2aeb-4c0c-b4fa-7d39d4504a5c",
   "metadata": {},
   "source": [
    "# ------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90f1695-8f14-42f7-9839-9d40750349b2",
   "metadata": {},
   "source": [
    "### Since the dataset given by Datacamp is only available in their web envirmonet, i'll make a project here, using a dataset called SVHN (Street View House Numbers), to develop the project and then i'll adapt it to the datacamp project :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "903408a2-d82a-43d4-9d9a-1fd1bfe03a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#from project_utils import ProjectDataset\n",
    "import pickle \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "# Load datasets\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5f47555-1e69-41af-997a-021316afb06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data\\train_32x32.mat\n",
      "Using downloaded and verified file: ./data\\test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.SVHN(root='./data', split='train', download=True, transform=transforms.ToTensor())\n",
    "test_data = datasets.SVHN(root='./data', split='test', download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c544e75-423a-4248-9721-9652af008054",
   "metadata": {},
   "source": [
    "# Lets visualize data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fde17a2b-67da-47a1-b2fc-369c3f545b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Training Dataset:  73257\n",
      "Size of Test Dataset:  26032\n",
      "\n",
      "Each batch has 20 images.\n",
      "Each sample is an image with 3 channel(s), and each image is 32x32 pixels.\n",
      "\n",
      "Shape of Features:  torch.Size([20, 3, 32, 32])\n",
      "Number of Unique Labels is 10.\n",
      "They are: [0 1 2 3 4 5 6 7 8 9].\n",
      "\n",
      "Lets see some of the data:\n",
      "\n",
      "Labels for Training: tensor([7, 5, 3, 0, 2, 3, 5, 1, 2, 0, 1, 1, 0, 2, 7, 4, 9, 8, 1, 1])\n",
      "Features for Training:tensor([[[[0.2706, 0.2902, 0.2824,  ..., 0.2431, 0.2510, 0.2627],\n",
      "          [0.2706, 0.2784, 0.2941,  ..., 0.2549, 0.2353, 0.2314],\n",
      "          [0.2824, 0.2863, 0.3059,  ..., 0.2863, 0.2627, 0.2471],\n",
      "          ...,\n",
      "          [0.3255, 0.3490, 0.3490,  ..., 0.6627, 0.6549, 0.6235],\n",
      "          [0.3451, 0.3647, 0.3765,  ..., 0.6980, 0.6784, 0.6353],\n",
      "          [0.3725, 0.3922, 0.4235,  ..., 0.7020, 0.6902, 0.6471]],\n",
      "\n",
      "         [[0.2588, 0.2863, 0.2863,  ..., 0.2667, 0.2745, 0.2863],\n",
      "          [0.2588, 0.2706, 0.2902,  ..., 0.2902, 0.2667, 0.2627],\n",
      "          [0.2706, 0.2784, 0.2980,  ..., 0.3255, 0.3020, 0.2863],\n",
      "          ...,\n",
      "          [0.3373, 0.3608, 0.3686,  ..., 0.7020, 0.6941, 0.6667],\n",
      "          [0.3647, 0.3765, 0.3922,  ..., 0.7333, 0.7137, 0.6706],\n",
      "          [0.4039, 0.4078, 0.4275,  ..., 0.7373, 0.7137, 0.6745]],\n",
      "\n",
      "         [[0.2863, 0.3059, 0.3020,  ..., 0.2588, 0.2745, 0.2863],\n",
      "          [0.2863, 0.2902, 0.3098,  ..., 0.2863, 0.2745, 0.2706],\n",
      "          [0.2980, 0.2980, 0.3176,  ..., 0.3294, 0.3059, 0.2902],\n",
      "          ...,\n",
      "          [0.3647, 0.3804, 0.3843,  ..., 0.6980, 0.6863, 0.6510],\n",
      "          [0.3882, 0.3961, 0.4039,  ..., 0.7216, 0.7020, 0.6510],\n",
      "          [0.4157, 0.4196, 0.4353,  ..., 0.7176, 0.6980, 0.6471]]],\n",
      "\n",
      "\n",
      "        [[[0.9882, 0.9804, 0.9608,  ..., 0.9961, 1.0000, 1.0000],\n",
      "          [0.9882, 0.9804, 0.9569,  ..., 0.9922, 0.9922, 0.9922],\n",
      "          [0.9882, 0.9725, 0.9451,  ..., 0.9843, 0.9843, 0.9843],\n",
      "          ...,\n",
      "          [0.9804, 0.9333, 0.8706,  ..., 0.9490, 0.9137, 0.8941],\n",
      "          [0.9922, 0.9608, 0.9098,  ..., 0.9725, 0.9608, 0.9529],\n",
      "          [1.0000, 0.9765, 0.9333,  ..., 0.9804, 0.9843, 0.9882]],\n",
      "\n",
      "         [[0.9922, 0.9843, 0.9647,  ..., 0.9961, 1.0000, 1.0000],\n",
      "          [0.9922, 0.9843, 0.9608,  ..., 0.9922, 0.9922, 0.9922],\n",
      "          [0.9922, 0.9765, 0.9490,  ..., 0.9843, 0.9843, 0.9843],\n",
      "          ...,\n",
      "          [0.9804, 0.9333, 0.8667,  ..., 0.9529, 0.9216, 0.9020],\n",
      "          [0.9922, 0.9569, 0.9059,  ..., 0.9843, 0.9725, 0.9686],\n",
      "          [1.0000, 0.9765, 0.9333,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "         [[1.0000, 0.9961, 0.9843,  ..., 0.9961, 1.0000, 1.0000],\n",
      "          [1.0000, 0.9961, 0.9765,  ..., 0.9922, 0.9961, 0.9961],\n",
      "          [1.0000, 0.9882, 0.9647,  ..., 0.9922, 0.9922, 0.9922],\n",
      "          ...,\n",
      "          [0.9843, 0.9451, 0.8863,  ..., 0.9686, 0.9412, 0.9255],\n",
      "          [0.9961, 0.9686, 0.9216,  ..., 0.9922, 0.9843, 0.9765],\n",
      "          [1.0000, 0.9804, 0.9412,  ..., 1.0000, 1.0000, 1.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.8745, 0.8745, 0.8745,  ..., 0.4667, 0.4471, 0.4353],\n",
      "          [0.8745, 0.8745, 0.8745,  ..., 0.4667, 0.4471, 0.4353],\n",
      "          [0.8745, 0.8745, 0.8745,  ..., 0.4667, 0.4392, 0.4275],\n",
      "          ...,\n",
      "          [0.7608, 0.7765, 0.8196,  ..., 0.2824, 0.2824, 0.2824],\n",
      "          [0.7529, 0.7725, 0.8196,  ..., 0.3176, 0.3176, 0.3176],\n",
      "          [0.7529, 0.7725, 0.8196,  ..., 0.3294, 0.3294, 0.3294]],\n",
      "\n",
      "         [[0.8784, 0.8784, 0.8784,  ..., 0.5490, 0.5294, 0.5176],\n",
      "          [0.8784, 0.8784, 0.8784,  ..., 0.5490, 0.5255, 0.5137],\n",
      "          [0.8824, 0.8824, 0.8784,  ..., 0.5412, 0.5176, 0.5059],\n",
      "          ...,\n",
      "          [0.7569, 0.7765, 0.8235,  ..., 0.3216, 0.3216, 0.3216],\n",
      "          [0.7529, 0.7725, 0.8196,  ..., 0.3529, 0.3569, 0.3569],\n",
      "          [0.7529, 0.7725, 0.8196,  ..., 0.3647, 0.3725, 0.3725]],\n",
      "\n",
      "         [[0.8980, 0.8980, 0.8941,  ..., 0.6627, 0.6431, 0.6314],\n",
      "          [0.8980, 0.8980, 0.8941,  ..., 0.6627, 0.6431, 0.6314],\n",
      "          [0.8980, 0.8980, 0.8941,  ..., 0.6667, 0.6431, 0.6314],\n",
      "          ...,\n",
      "          [0.7922, 0.8078, 0.8471,  ..., 0.4275, 0.4235, 0.4235],\n",
      "          [0.7882, 0.8039, 0.8431,  ..., 0.4431, 0.4471, 0.4471],\n",
      "          [0.7882, 0.8039, 0.8431,  ..., 0.4510, 0.4588, 0.4588]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.4431, 0.4196, 0.3765,  ..., 0.1882, 0.2000, 0.2039],\n",
      "          [0.4275, 0.4000, 0.3529,  ..., 0.1882, 0.2039, 0.2078],\n",
      "          [0.3922, 0.3608, 0.3059,  ..., 0.1922, 0.2078, 0.2118],\n",
      "          ...,\n",
      "          [0.2196, 0.2157, 0.2118,  ..., 0.1961, 0.1922, 0.1882],\n",
      "          [0.1725, 0.1725, 0.1725,  ..., 0.2039, 0.2000, 0.2000],\n",
      "          [0.1451, 0.1451, 0.1490,  ..., 0.2078, 0.2078, 0.2078]],\n",
      "\n",
      "         [[0.4824, 0.4588, 0.4196,  ..., 0.1882, 0.1922, 0.1922],\n",
      "          [0.4588, 0.4314, 0.3843,  ..., 0.1882, 0.1922, 0.1922],\n",
      "          [0.4235, 0.3882, 0.3333,  ..., 0.1843, 0.1882, 0.1882],\n",
      "          ...,\n",
      "          [0.2471, 0.2471, 0.2471,  ..., 0.1922, 0.1882, 0.1882],\n",
      "          [0.1961, 0.1961, 0.2000,  ..., 0.1843, 0.1843, 0.1843],\n",
      "          [0.1686, 0.1686, 0.1725,  ..., 0.1804, 0.1843, 0.1843]],\n",
      "\n",
      "         [[0.4863, 0.4627, 0.4235,  ..., 0.2275, 0.2275, 0.2275],\n",
      "          [0.4784, 0.4549, 0.4078,  ..., 0.2314, 0.2314, 0.2314],\n",
      "          [0.4627, 0.4353, 0.3843,  ..., 0.2353, 0.2353, 0.2353],\n",
      "          ...,\n",
      "          [0.2824, 0.2784, 0.2706,  ..., 0.2118, 0.1961, 0.1882],\n",
      "          [0.2392, 0.2392, 0.2431,  ..., 0.2078, 0.1961, 0.1922],\n",
      "          [0.2157, 0.2157, 0.2235,  ..., 0.2078, 0.1961, 0.1922]]],\n",
      "\n",
      "\n",
      "        [[[0.4000, 0.3961, 0.4000,  ..., 0.3804, 0.3961, 0.3804],\n",
      "          [0.4157, 0.4157, 0.4196,  ..., 0.5098, 0.5294, 0.5333],\n",
      "          [0.4235, 0.4196, 0.4235,  ..., 0.6627, 0.6824, 0.6784],\n",
      "          ...,\n",
      "          [0.4471, 0.4431, 0.4392,  ..., 0.4235, 0.4392, 0.4471],\n",
      "          [0.4392, 0.4392, 0.4314,  ..., 0.4353, 0.4431, 0.4549],\n",
      "          [0.4353, 0.4353, 0.4275,  ..., 0.4549, 0.4588, 0.4667]],\n",
      "\n",
      "         [[0.3686, 0.3647, 0.3686,  ..., 0.3843, 0.4000, 0.4039],\n",
      "          [0.3882, 0.3882, 0.3922,  ..., 0.5373, 0.5569, 0.5725],\n",
      "          [0.4000, 0.3961, 0.4000,  ..., 0.7098, 0.7255, 0.7333],\n",
      "          ...,\n",
      "          [0.3804, 0.3686, 0.3608,  ..., 0.3882, 0.3843, 0.3725],\n",
      "          [0.3804, 0.3725, 0.3608,  ..., 0.3961, 0.3843, 0.3804],\n",
      "          [0.3804, 0.3686, 0.3569,  ..., 0.4039, 0.3961, 0.4039]],\n",
      "\n",
      "         [[0.2941, 0.2902, 0.2941,  ..., 0.4549, 0.4627, 0.4471],\n",
      "          [0.3216, 0.3176, 0.3216,  ..., 0.6000, 0.6157, 0.6118],\n",
      "          [0.3373, 0.3333, 0.3373,  ..., 0.7490, 0.7608, 0.7647],\n",
      "          ...,\n",
      "          [0.3490, 0.3451, 0.3412,  ..., 0.3882, 0.3961, 0.3922],\n",
      "          [0.3451, 0.3412, 0.3333,  ..., 0.3961, 0.3961, 0.3882],\n",
      "          [0.3451, 0.3373, 0.3255,  ..., 0.4000, 0.4000, 0.4039]]],\n",
      "\n",
      "\n",
      "        [[[0.9137, 0.9216, 0.9098,  ..., 0.8471, 0.8431, 0.8392],\n",
      "          [0.9098, 0.9098, 0.9137,  ..., 0.7647, 0.7451, 0.7412],\n",
      "          [0.9020, 0.9059, 0.9098,  ..., 0.6039, 0.5608, 0.5412],\n",
      "          ...,\n",
      "          [0.9137, 0.9137, 0.9098,  ..., 0.4824, 0.4392, 0.4314],\n",
      "          [0.9137, 0.9137, 0.9137,  ..., 0.6275, 0.6039, 0.6078],\n",
      "          [0.9216, 0.9176, 0.9176,  ..., 0.7569, 0.7451, 0.7451]],\n",
      "\n",
      "         [[0.8980, 0.9020, 0.8941,  ..., 0.8549, 0.8549, 0.8588],\n",
      "          [0.8902, 0.8941, 0.8980,  ..., 0.7843, 0.7765, 0.7804],\n",
      "          [0.8824, 0.8902, 0.8980,  ..., 0.6431, 0.6157, 0.6118],\n",
      "          ...,\n",
      "          [0.8824, 0.8863, 0.8902,  ..., 0.4667, 0.4157, 0.3961],\n",
      "          [0.8824, 0.8863, 0.8902,  ..., 0.6157, 0.5843, 0.5765],\n",
      "          [0.8824, 0.8824, 0.8863,  ..., 0.7333, 0.7216, 0.7137]],\n",
      "\n",
      "         [[0.8627, 0.8745, 0.8667,  ..., 0.8706, 0.8745, 0.8745],\n",
      "          [0.8627, 0.8706, 0.8784,  ..., 0.8314, 0.8235, 0.8235],\n",
      "          [0.8588, 0.8706, 0.8824,  ..., 0.7333, 0.7059, 0.6941],\n",
      "          ...,\n",
      "          [0.8392, 0.8431, 0.8510,  ..., 0.5451, 0.5098, 0.5059],\n",
      "          [0.8392, 0.8431, 0.8549,  ..., 0.6549, 0.6471, 0.6549],\n",
      "          [0.8431, 0.8510, 0.8627,  ..., 0.7529, 0.7490, 0.7608]]]])\n"
     ]
    }
   ],
   "source": [
    "# Lets see the size of the dataset\n",
    "print(\"Size of Training Dataset: \", len(train_data))\n",
    "print(\"Size of Test Dataset: \", len(test_data))\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 20\n",
    "# Lets define now the dataloaders for each set\n",
    "dataloader_train = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "dataloader_test = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Lets get feautes and labels\n",
    "images, labels = next(iter(dataloader_train))\n",
    "\n",
    "# Lets get a summary\n",
    "batch_size, channels, height, width = images.shape\n",
    "print(f\"\\nEach batch has {batch_size} images.\\nEach sample is an image with {channels} channel(s), and each image is {height}x{width} pixels.\")\n",
    "print(\"\\nShape of Features: \", images.shape)\n",
    "\n",
    "# Lets see how many labes there are\n",
    "unique_labels = np.unique(train_data.labels)\n",
    "n_unique_labels = len(unique_labels)\n",
    "print(f\"Number of Unique Labels is {n_unique_labels}.\\nThey are: {unique_labels}.\")\n",
    "\n",
    "# Lets see some data\n",
    "print(\"\\nLets see some of the data:\")\n",
    "print(f\"\\nLabels for Training: {labels}\\nFeatures for Training:{images}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d52eac5-de33-4ed7-9a6c-a81359eefcda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lets see some images of the data set\n",
    "def show_images(dataloader, num_images):\n",
    "\n",
    "    # Get a batch of data\n",
    "    images, labels = next(iter(dataloader))\n",
    "    \n",
    "    # Plot images\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(15, 3))\n",
    "    for i in range(num_images):\n",
    "        # Unnormalize the image (from Tensor to numpy array)\n",
    "        image = images[i].numpy().transpose((1, 2, 0))  # (C, H, W) to (H, W, C)\n",
    "        # Plot image\n",
    "        axes[i].imshow(image)\n",
    "        axes[i].set_title(f'Label: {labels[i].item()}')\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Display the first 5 images from the training dataset\n",
    "n_images = 10\n",
    "show_images(dataloader_train, n_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c297f310-3643-4b01-856b-ae120e8db1fb",
   "metadata": {},
   "source": [
    "# Lets define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44aafc8e-1459-4667-982f-e341878738cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets define the a class for the model\n",
    "class OCRModel(nn.Module):\n",
    "\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        # Define a block that will extract features from images\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            # First Conv Layer\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1), # 16 x 32 x 32\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2), # 16 x 16 x 16\n",
    "            # Second Conv Layer\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1), # 32 x 16 x 16\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2), # 32 x 8 x 8\n",
    "            # Third Conv Layer\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1), # 64 x 8 x 8\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2), # 64 x 4 x 4\n",
    "            # Flatten Layer\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        # Add a Linear Layer\n",
    "        self.classifier = nn.Linear(64 * 4 * 4, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef68eee6-7f26-4e86-bcf5-fab68639d1dc",
   "metadata": {},
   "source": [
    "# Some parameters before tranning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "933bf703-1a2b-4dfd-8620-12c1dc49744a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      " OCRModel(\n",
      "  (feature_extractor): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (classifier): Linear(in_features=1024, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = OCRModel(n_unique_labels)\n",
    "print(\"Model Summary:\\n\",model)\n",
    "\n",
    "# Define the optimizer\n",
    "learning_rate = 0.001\n",
    "    \n",
    "# Define variables to training loop\n",
    "num_epochs = 45\n",
    "total_steps = len(dataloader_train)\n",
    "\n",
    "# Define the loss we will lose\n",
    "loss_criterion = nn.CrossEntropyLoss() # Commonly used as a loss function in classification tasks,\n",
    "                                       # especially when the model outputs probabilities\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "# Define paths for saving and loading the CNN\n",
    "OCR_model_path = 'OCR_CNN_model.pth'\n",
    "lossEpoch_graph_path = 'lossEpoch_graph.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3de4146-3b88-4f8c-8b93-ffd8a0a73940",
   "metadata": {},
   "source": [
    "# Lets make the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8145a468-5d9f-46b0-aed2-9e7936472dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No molde saved found -> Beginning Training...\n",
      "\n",
      "DONT FORGET:\n",
      "Training data has 73257 images and the batch size is 20.\n",
      "\n",
      "Epoch 1 began!\n",
      "Epoch [1/45], Step [100/3663], Loss: 2.2423\n",
      "Epoch [1/45], Step [200/3663], Loss: 2.2430\n",
      "Epoch [1/45], Step [300/3663], Loss: 2.2246\n",
      "Epoch [1/45], Step [400/3663], Loss: 2.1945\n",
      "Epoch [1/45], Step [500/3663], Loss: 1.9409\n",
      "Epoch [1/45], Step [600/3663], Loss: 1.6241\n",
      "Epoch [1/45], Step [700/3663], Loss: 1.3689\n",
      "Epoch [1/45], Step [800/3663], Loss: 1.0958\n",
      "Epoch [1/45], Step [900/3663], Loss: 1.0385\n",
      "Epoch [1/45], Step [1000/3663], Loss: 0.9393\n",
      "Epoch [1/45], Step [1100/3663], Loss: 0.9131\n",
      "Epoch [1/45], Step [1200/3663], Loss: 0.7877\n",
      "Epoch [1/45], Step [1300/3663], Loss: 0.8049\n",
      "Epoch [1/45], Step [1400/3663], Loss: 0.7678\n",
      "Epoch [1/45], Step [1500/3663], Loss: 0.7289\n",
      "Epoch [1/45], Step [1600/3663], Loss: 0.7252\n",
      "Epoch [1/45], Step [1700/3663], Loss: 0.7049\n",
      "Epoch [1/45], Step [1800/3663], Loss: 0.7206\n",
      "Epoch [1/45], Step [1900/3663], Loss: 0.6536\n",
      "Epoch [1/45], Step [2000/3663], Loss: 0.6116\n",
      "Epoch [1/45], Step [2100/3663], Loss: 0.6198\n",
      "Epoch [1/45], Step [2200/3663], Loss: 0.6468\n",
      "Epoch [1/45], Step [2300/3663], Loss: 0.6256\n",
      "Epoch [1/45], Step [2400/3663], Loss: 0.6185\n",
      "Epoch [1/45], Step [2500/3663], Loss: 0.6270\n",
      "Epoch [1/45], Step [2600/3663], Loss: 0.6305\n",
      "Epoch [1/45], Step [2700/3663], Loss: 0.5958\n",
      "Epoch [1/45], Step [2800/3663], Loss: 0.5969\n",
      "Epoch [1/45], Step [2900/3663], Loss: 0.5785\n",
      "Epoch [1/45], Step [3000/3663], Loss: 0.6316\n",
      "Epoch [1/45], Step [3100/3663], Loss: 0.5765\n",
      "Epoch [1/45], Step [3200/3663], Loss: 0.5283\n",
      "Epoch [1/45], Step [3300/3663], Loss: 0.5571\n",
      "Epoch [1/45], Step [3400/3663], Loss: 0.5536\n",
      "Epoch [1/45], Step [3500/3663], Loss: 0.5663\n",
      "Epoch [1/45], Step [3600/3663], Loss: 0.5617\n",
      "Loss of Epoch 1: 0.933015051448106\n",
      "Epoch 2 began!\n",
      "Epoch [2/45], Step [100/3663], Loss: 0.4869\n",
      "Epoch [2/45], Step [200/3663], Loss: 0.5291\n",
      "Epoch [2/45], Step [300/3663], Loss: 0.5307\n",
      "Epoch [2/45], Step [400/3663], Loss: 0.4926\n",
      "Epoch [2/45], Step [500/3663], Loss: 0.5251\n",
      "Epoch [2/45], Step [600/3663], Loss: 0.4968\n",
      "Epoch [2/45], Step [700/3663], Loss: 0.5173\n",
      "Epoch [2/45], Step [800/3663], Loss: 0.4813\n",
      "Epoch [2/45], Step [900/3663], Loss: 0.5422\n",
      "Epoch [2/45], Step [1000/3663], Loss: 0.4940\n",
      "Epoch [2/45], Step [1100/3663], Loss: 0.4966\n",
      "Epoch [2/45], Step [1200/3663], Loss: 0.5084\n",
      "Epoch [2/45], Step [1300/3663], Loss: 0.4533\n",
      "Epoch [2/45], Step [1400/3663], Loss: 0.5069\n",
      "Epoch [2/45], Step [1500/3663], Loss: 0.4906\n",
      "Epoch [2/45], Step [1600/3663], Loss: 0.5279\n",
      "Epoch [2/45], Step [1700/3663], Loss: 0.4670\n",
      "Epoch [2/45], Step [1800/3663], Loss: 0.5451\n",
      "Epoch [2/45], Step [1900/3663], Loss: 0.4935\n",
      "Epoch [2/45], Step [2000/3663], Loss: 0.4853\n",
      "Epoch [2/45], Step [2100/3663], Loss: 0.5478\n",
      "Epoch [2/45], Step [2200/3663], Loss: 0.4851\n",
      "Epoch [2/45], Step [2300/3663], Loss: 0.4800\n",
      "Epoch [2/45], Step [2400/3663], Loss: 0.5123\n",
      "Epoch [2/45], Step [2500/3663], Loss: 0.4408\n",
      "Epoch [2/45], Step [2600/3663], Loss: 0.4812\n",
      "Epoch [2/45], Step [2700/3663], Loss: 0.4405\n",
      "Epoch [2/45], Step [2800/3663], Loss: 0.5025\n",
      "Epoch [2/45], Step [2900/3663], Loss: 0.4757\n",
      "Epoch [2/45], Step [3000/3663], Loss: 0.4651\n",
      "Epoch [2/45], Step [3100/3663], Loss: 0.4706\n",
      "Epoch [2/45], Step [3200/3663], Loss: 0.4784\n",
      "Epoch [2/45], Step [3300/3663], Loss: 0.4807\n",
      "Epoch [2/45], Step [3400/3663], Loss: 0.4584\n",
      "Epoch [2/45], Step [3500/3663], Loss: 0.4469\n",
      "Epoch [2/45], Step [3600/3663], Loss: 0.4497\n",
      "Loss of Epoch 2: 0.49052335258137\n",
      "Epoch 3 began!\n",
      "Epoch [3/45], Step [100/3663], Loss: 0.4304\n",
      "Epoch [3/45], Step [200/3663], Loss: 0.4032\n",
      "Epoch [3/45], Step [300/3663], Loss: 0.4386\n",
      "Epoch [3/45], Step [400/3663], Loss: 0.4087\n",
      "Epoch [3/45], Step [500/3663], Loss: 0.4249\n",
      "Epoch [3/45], Step [600/3663], Loss: 0.3977\n",
      "Epoch [3/45], Step [700/3663], Loss: 0.4404\n",
      "Epoch [3/45], Step [800/3663], Loss: 0.4273\n",
      "Epoch [3/45], Step [900/3663], Loss: 0.4420\n",
      "Epoch [3/45], Step [1000/3663], Loss: 0.4310\n",
      "Epoch [3/45], Step [1100/3663], Loss: 0.4035\n",
      "Epoch [3/45], Step [1200/3663], Loss: 0.4013\n",
      "Epoch [3/45], Step [1300/3663], Loss: 0.3854\n",
      "Epoch [3/45], Step [1400/3663], Loss: 0.4423\n",
      "Epoch [3/45], Step [1500/3663], Loss: 0.4097\n",
      "Epoch [3/45], Step [1600/3663], Loss: 0.4363\n",
      "Epoch [3/45], Step [1700/3663], Loss: 0.4225\n",
      "Epoch [3/45], Step [1800/3663], Loss: 0.4240\n",
      "Epoch [3/45], Step [1900/3663], Loss: 0.4203\n",
      "Epoch [3/45], Step [2000/3663], Loss: 0.4267\n",
      "Epoch [3/45], Step [2100/3663], Loss: 0.4120\n",
      "Epoch [3/45], Step [2200/3663], Loss: 0.4413\n",
      "Epoch [3/45], Step [2300/3663], Loss: 0.4551\n",
      "Epoch [3/45], Step [2400/3663], Loss: 0.4568\n",
      "Epoch [3/45], Step [2500/3663], Loss: 0.3799\n",
      "Epoch [3/45], Step [2600/3663], Loss: 0.4173\n",
      "Epoch [3/45], Step [2700/3663], Loss: 0.4217\n",
      "Epoch [3/45], Step [2800/3663], Loss: 0.4553\n",
      "Epoch [3/45], Step [2900/3663], Loss: 0.4053\n",
      "Epoch [3/45], Step [3000/3663], Loss: 0.4190\n",
      "Epoch [3/45], Step [3100/3663], Loss: 0.4744\n",
      "Epoch [3/45], Step [3200/3663], Loss: 0.4531\n",
      "Epoch [3/45], Step [3300/3663], Loss: 0.4351\n",
      "Epoch [3/45], Step [3400/3663], Loss: 0.4257\n",
      "Epoch [3/45], Step [3500/3663], Loss: 0.4306\n",
      "Epoch [3/45], Step [3600/3663], Loss: 0.4190\n",
      "Loss of Epoch 3: 0.4258986778309151\n",
      "Epoch 4 began!\n",
      "Epoch [4/45], Step [100/3663], Loss: 0.3857\n",
      "Epoch [4/45], Step [200/3663], Loss: 0.3392\n",
      "Epoch [4/45], Step [300/3663], Loss: 0.3576\n",
      "Epoch [4/45], Step [400/3663], Loss: 0.3620\n",
      "Epoch [4/45], Step [500/3663], Loss: 0.4065\n",
      "Epoch [4/45], Step [600/3663], Loss: 0.3407\n",
      "Epoch [4/45], Step [700/3663], Loss: 0.3797\n",
      "Epoch [4/45], Step [800/3663], Loss: 0.3880\n",
      "Epoch [4/45], Step [900/3663], Loss: 0.3819\n",
      "Epoch [4/45], Step [1000/3663], Loss: 0.3906\n",
      "Epoch [4/45], Step [1100/3663], Loss: 0.4248\n",
      "Epoch [4/45], Step [1200/3663], Loss: 0.3921\n",
      "Epoch [4/45], Step [1300/3663], Loss: 0.3621\n",
      "Epoch [4/45], Step [1400/3663], Loss: 0.4097\n",
      "Epoch [4/45], Step [1500/3663], Loss: 0.3757\n",
      "Epoch [4/45], Step [1600/3663], Loss: 0.3729\n",
      "Epoch [4/45], Step [1700/3663], Loss: 0.3749\n",
      "Epoch [4/45], Step [1800/3663], Loss: 0.3997\n",
      "Epoch [4/45], Step [1900/3663], Loss: 0.4049\n",
      "Epoch [4/45], Step [2000/3663], Loss: 0.3572\n",
      "Epoch [4/45], Step [2100/3663], Loss: 0.3922\n",
      "Epoch [4/45], Step [2200/3663], Loss: 0.4262\n",
      "Epoch [4/45], Step [2300/3663], Loss: 0.4303\n",
      "Epoch [4/45], Step [2400/3663], Loss: 0.3740\n",
      "Epoch [4/45], Step [2500/3663], Loss: 0.4011\n",
      "Epoch [4/45], Step [2600/3663], Loss: 0.3899\n",
      "Epoch [4/45], Step [2700/3663], Loss: 0.3558\n",
      "Epoch [4/45], Step [2800/3663], Loss: 0.3858\n",
      "Epoch [4/45], Step [2900/3663], Loss: 0.3889\n",
      "Epoch [4/45], Step [3000/3663], Loss: 0.3519\n",
      "Epoch [4/45], Step [3100/3663], Loss: 0.3620\n",
      "Epoch [4/45], Step [3200/3663], Loss: 0.3864\n",
      "Epoch [4/45], Step [3300/3663], Loss: 0.3810\n",
      "Epoch [4/45], Step [3400/3663], Loss: 0.4101\n",
      "Epoch [4/45], Step [3500/3663], Loss: 0.4427\n",
      "Epoch [4/45], Step [3600/3663], Loss: 0.3917\n",
      "Loss of Epoch 4: 0.38575421240986196\n",
      "Epoch 5 began!\n",
      "Epoch [5/45], Step [100/3663], Loss: 0.3277\n",
      "Epoch [5/45], Step [200/3663], Loss: 0.3637\n",
      "Epoch [5/45], Step [300/3663], Loss: 0.3343\n",
      "Epoch [5/45], Step [400/3663], Loss: 0.3618\n",
      "Epoch [5/45], Step [500/3663], Loss: 0.3229\n",
      "Epoch [5/45], Step [600/3663], Loss: 0.3449\n",
      "Epoch [5/45], Step [700/3663], Loss: 0.3075\n",
      "Epoch [5/45], Step [800/3663], Loss: 0.3507\n",
      "Epoch [5/45], Step [900/3663], Loss: 0.3749\n",
      "Epoch [5/45], Step [1000/3663], Loss: 0.3652\n",
      "Epoch [5/45], Step [1100/3663], Loss: 0.3651\n",
      "Epoch [5/45], Step [1200/3663], Loss: 0.3569\n",
      "Epoch [5/45], Step [1300/3663], Loss: 0.3789\n",
      "Epoch [5/45], Step [1400/3663], Loss: 0.3772\n",
      "Epoch [5/45], Step [1500/3663], Loss: 0.3351\n",
      "Epoch [5/45], Step [1600/3663], Loss: 0.3798\n",
      "Epoch [5/45], Step [1700/3663], Loss: 0.3650\n",
      "Epoch [5/45], Step [1800/3663], Loss: 0.3501\n",
      "Epoch [5/45], Step [1900/3663], Loss: 0.3415\n",
      "Epoch [5/45], Step [2000/3663], Loss: 0.3850\n",
      "Epoch [5/45], Step [2100/3663], Loss: 0.3417\n",
      "Epoch [5/45], Step [2200/3663], Loss: 0.3627\n",
      "Epoch [5/45], Step [2300/3663], Loss: 0.3518\n",
      "Epoch [5/45], Step [2400/3663], Loss: 0.3526\n",
      "Epoch [5/45], Step [2500/3663], Loss: 0.3627\n",
      "Epoch [5/45], Step [2600/3663], Loss: 0.3217\n",
      "Epoch [5/45], Step [2700/3663], Loss: 0.3942\n",
      "Epoch [5/45], Step [2800/3663], Loss: 0.3650\n",
      "Epoch [5/45], Step [2900/3663], Loss: 0.3733\n",
      "Epoch [5/45], Step [3000/3663], Loss: 0.3444\n",
      "Epoch [5/45], Step [3100/3663], Loss: 0.3908\n",
      "Epoch [5/45], Step [3200/3663], Loss: 0.3682\n",
      "Epoch [5/45], Step [3300/3663], Loss: 0.4143\n",
      "Epoch [5/45], Step [3400/3663], Loss: 0.3410\n",
      "Epoch [5/45], Step [3500/3663], Loss: 0.3691\n",
      "Epoch [5/45], Step [3600/3663], Loss: 0.3660\n",
      "Loss of Epoch 5: 0.3585039464364791\n",
      "Epoch 6 began!\n",
      "Epoch [6/45], Step [100/3663], Loss: 0.3080\n",
      "Epoch [6/45], Step [200/3663], Loss: 0.3448\n",
      "Epoch [6/45], Step [300/3663], Loss: 0.3304\n",
      "Epoch [6/45], Step [400/3663], Loss: 0.2893\n",
      "Epoch [6/45], Step [500/3663], Loss: 0.3334\n",
      "Epoch [6/45], Step [600/3663], Loss: 0.3257\n",
      "Epoch [6/45], Step [700/3663], Loss: 0.3637\n",
      "Epoch [6/45], Step [800/3663], Loss: 0.3418\n",
      "Epoch [6/45], Step [900/3663], Loss: 0.3580\n",
      "Epoch [6/45], Step [1000/3663], Loss: 0.3164\n",
      "Epoch [6/45], Step [1100/3663], Loss: 0.3336\n",
      "Epoch [6/45], Step [1200/3663], Loss: 0.3344\n",
      "Epoch [6/45], Step [1300/3663], Loss: 0.3111\n",
      "Epoch [6/45], Step [1400/3663], Loss: 0.3528\n",
      "Epoch [6/45], Step [1500/3663], Loss: 0.3447\n",
      "Epoch [6/45], Step [1600/3663], Loss: 0.3401\n",
      "Epoch [6/45], Step [1700/3663], Loss: 0.3185\n",
      "Epoch [6/45], Step [1800/3663], Loss: 0.3421\n",
      "Epoch [6/45], Step [1900/3663], Loss: 0.3619\n",
      "Epoch [6/45], Step [2000/3663], Loss: 0.3367\n",
      "Epoch [6/45], Step [2100/3663], Loss: 0.3140\n",
      "Epoch [6/45], Step [2200/3663], Loss: 0.3315\n",
      "Epoch [6/45], Step [2300/3663], Loss: 0.3333\n",
      "Epoch [6/45], Step [2400/3663], Loss: 0.3587\n",
      "Epoch [6/45], Step [2500/3663], Loss: 0.3071\n",
      "Epoch [6/45], Step [2600/3663], Loss: 0.3365\n",
      "Epoch [6/45], Step [2700/3663], Loss: 0.3187\n",
      "Epoch [6/45], Step [2800/3663], Loss: 0.3576\n",
      "Epoch [6/45], Step [2900/3663], Loss: 0.2986\n",
      "Epoch [6/45], Step [3000/3663], Loss: 0.3467\n",
      "Epoch [6/45], Step [3100/3663], Loss: 0.3714\n",
      "Epoch [6/45], Step [3200/3663], Loss: 0.3194\n",
      "Epoch [6/45], Step [3300/3663], Loss: 0.3370\n",
      "Epoch [6/45], Step [3400/3663], Loss: 0.3372\n",
      "Epoch [6/45], Step [3500/3663], Loss: 0.3402\n",
      "Epoch [6/45], Step [3600/3663], Loss: 0.3767\n",
      "Loss of Epoch 6: 0.3356599401084616\n",
      "Epoch 7 began!\n",
      "Epoch [7/45], Step [100/3663], Loss: 0.3168\n",
      "Epoch [7/45], Step [200/3663], Loss: 0.3171\n",
      "Epoch [7/45], Step [300/3663], Loss: 0.2989\n",
      "Epoch [7/45], Step [400/3663], Loss: 0.3036\n",
      "Epoch [7/45], Step [500/3663], Loss: 0.3065\n",
      "Epoch [7/45], Step [600/3663], Loss: 0.3059\n",
      "Epoch [7/45], Step [700/3663], Loss: 0.3338\n",
      "Epoch [7/45], Step [800/3663], Loss: 0.3371\n",
      "Epoch [7/45], Step [900/3663], Loss: 0.3356\n",
      "Epoch [7/45], Step [1000/3663], Loss: 0.2864\n",
      "Epoch [7/45], Step [1100/3663], Loss: 0.3340\n",
      "Epoch [7/45], Step [1200/3663], Loss: 0.3001\n",
      "Epoch [7/45], Step [1300/3663], Loss: 0.3275\n",
      "Epoch [7/45], Step [1400/3663], Loss: 0.3168\n",
      "Epoch [7/45], Step [1500/3663], Loss: 0.3414\n",
      "Epoch [7/45], Step [1600/3663], Loss: 0.3262\n",
      "Epoch [7/45], Step [1700/3663], Loss: 0.3358\n",
      "Epoch [7/45], Step [1800/3663], Loss: 0.3316\n",
      "Epoch [7/45], Step [1900/3663], Loss: 0.3032\n",
      "Epoch [7/45], Step [2000/3663], Loss: 0.2936\n",
      "Epoch [7/45], Step [2100/3663], Loss: 0.3662\n",
      "Epoch [7/45], Step [2200/3663], Loss: 0.3857\n",
      "Epoch [7/45], Step [2300/3663], Loss: 0.3129\n",
      "Epoch [7/45], Step [2400/3663], Loss: 0.3358\n",
      "Epoch [7/45], Step [2500/3663], Loss: 0.3349\n",
      "Epoch [7/45], Step [2600/3663], Loss: 0.3203\n",
      "Epoch [7/45], Step [2700/3663], Loss: 0.3189\n",
      "Epoch [7/45], Step [2800/3663], Loss: 0.2903\n",
      "Epoch [7/45], Step [2900/3663], Loss: 0.3344\n",
      "Epoch [7/45], Step [3000/3663], Loss: 0.3312\n",
      "Epoch [7/45], Step [3100/3663], Loss: 0.3472\n",
      "Epoch [7/45], Step [3200/3663], Loss: 0.2928\n",
      "Epoch [7/45], Step [3300/3663], Loss: 0.3273\n",
      "Epoch [7/45], Step [3400/3663], Loss: 0.3188\n",
      "Epoch [7/45], Step [3500/3663], Loss: 0.3001\n",
      "Epoch [7/45], Step [3600/3663], Loss: 0.3006\n",
      "Loss of Epoch 7: 0.3217793578549471\n",
      "Epoch 8 began!\n",
      "Epoch [8/45], Step [100/3663], Loss: 0.3097\n",
      "Epoch [8/45], Step [200/3663], Loss: 0.2973\n",
      "Epoch [8/45], Step [300/3663], Loss: 0.2850\n",
      "Epoch [8/45], Step [400/3663], Loss: 0.3438\n",
      "Epoch [8/45], Step [500/3663], Loss: 0.3059\n",
      "Epoch [8/45], Step [600/3663], Loss: 0.3205\n",
      "Epoch [8/45], Step [700/3663], Loss: 0.3118\n",
      "Epoch [8/45], Step [800/3663], Loss: 0.2747\n",
      "Epoch [8/45], Step [900/3663], Loss: 0.2978\n",
      "Epoch [8/45], Step [1000/3663], Loss: 0.2888\n",
      "Epoch [8/45], Step [1100/3663], Loss: 0.3383\n",
      "Epoch [8/45], Step [1200/3663], Loss: 0.2976\n",
      "Epoch [8/45], Step [1300/3663], Loss: 0.3220\n",
      "Epoch [8/45], Step [1400/3663], Loss: 0.2906\n",
      "Epoch [8/45], Step [1500/3663], Loss: 0.2924\n",
      "Epoch [8/45], Step [1600/3663], Loss: 0.2779\n",
      "Epoch [8/45], Step [1700/3663], Loss: 0.2792\n",
      "Epoch [8/45], Step [1800/3663], Loss: 0.3057\n",
      "Epoch [8/45], Step [1900/3663], Loss: 0.2954\n",
      "Epoch [8/45], Step [2000/3663], Loss: 0.3020\n",
      "Epoch [8/45], Step [2100/3663], Loss: 0.2911\n",
      "Epoch [8/45], Step [2200/3663], Loss: 0.3213\n",
      "Epoch [8/45], Step [2300/3663], Loss: 0.2667\n",
      "Epoch [8/45], Step [2400/3663], Loss: 0.3309\n",
      "Epoch [8/45], Step [2500/3663], Loss: 0.2943\n",
      "Epoch [8/45], Step [2600/3663], Loss: 0.3431\n",
      "Epoch [8/45], Step [2700/3663], Loss: 0.3337\n",
      "Epoch [8/45], Step [2800/3663], Loss: 0.2966\n",
      "Epoch [8/45], Step [2900/3663], Loss: 0.3564\n",
      "Epoch [8/45], Step [3000/3663], Loss: 0.3342\n",
      "Epoch [8/45], Step [3100/3663], Loss: 0.3164\n",
      "Epoch [8/45], Step [3200/3663], Loss: 0.3476\n",
      "Epoch [8/45], Step [3300/3663], Loss: 0.3008\n",
      "Epoch [8/45], Step [3400/3663], Loss: 0.3260\n",
      "Epoch [8/45], Step [3500/3663], Loss: 0.2803\n",
      "Epoch [8/45], Step [3600/3663], Loss: 0.2712\n",
      "Loss of Epoch 8: 0.306398895921538\n",
      "Epoch 9 began!\n",
      "Epoch [9/45], Step [100/3663], Loss: 0.2710\n",
      "Epoch [9/45], Step [200/3663], Loss: 0.2880\n",
      "Epoch [9/45], Step [300/3663], Loss: 0.2599\n",
      "Epoch [9/45], Step [400/3663], Loss: 0.2902\n",
      "Epoch [9/45], Step [500/3663], Loss: 0.3104\n",
      "Epoch [9/45], Step [600/3663], Loss: 0.2724\n",
      "Epoch [9/45], Step [700/3663], Loss: 0.3101\n",
      "Epoch [9/45], Step [800/3663], Loss: 0.3230\n",
      "Epoch [9/45], Step [900/3663], Loss: 0.2764\n",
      "Epoch [9/45], Step [1000/3663], Loss: 0.3005\n",
      "Epoch [9/45], Step [1100/3663], Loss: 0.3092\n",
      "Epoch [9/45], Step [1200/3663], Loss: 0.2884\n",
      "Epoch [9/45], Step [1300/3663], Loss: 0.2855\n",
      "Epoch [9/45], Step [1400/3663], Loss: 0.2940\n",
      "Epoch [9/45], Step [1500/3663], Loss: 0.3080\n",
      "Epoch [9/45], Step [1600/3663], Loss: 0.2684\n",
      "Epoch [9/45], Step [1700/3663], Loss: 0.2982\n",
      "Epoch [9/45], Step [1800/3663], Loss: 0.3027\n",
      "Epoch [9/45], Step [1900/3663], Loss: 0.2962\n",
      "Epoch [9/45], Step [2000/3663], Loss: 0.2926\n",
      "Epoch [9/45], Step [2100/3663], Loss: 0.2983\n",
      "Epoch [9/45], Step [2200/3663], Loss: 0.3030\n",
      "Epoch [9/45], Step [2300/3663], Loss: 0.3181\n",
      "Epoch [9/45], Step [2400/3663], Loss: 0.2771\n",
      "Epoch [9/45], Step [2500/3663], Loss: 0.3288\n",
      "Epoch [9/45], Step [2600/3663], Loss: 0.2798\n",
      "Epoch [9/45], Step [2700/3663], Loss: 0.2965\n",
      "Epoch [9/45], Step [2800/3663], Loss: 0.3001\n",
      "Epoch [9/45], Step [2900/3663], Loss: 0.3280\n",
      "Epoch [9/45], Step [3000/3663], Loss: 0.2793\n",
      "Epoch [9/45], Step [3100/3663], Loss: 0.3072\n",
      "Epoch [9/45], Step [3200/3663], Loss: 0.3015\n",
      "Epoch [9/45], Step [3300/3663], Loss: 0.2941\n",
      "Epoch [9/45], Step [3400/3663], Loss: 0.3128\n",
      "Epoch [9/45], Step [3500/3663], Loss: 0.3139\n",
      "Epoch [9/45], Step [3600/3663], Loss: 0.3312\n",
      "Loss of Epoch 9: 0.2970531588593671\n",
      "Epoch 10 began!\n",
      "Epoch [10/45], Step [100/3663], Loss: 0.2604\n",
      "Epoch [10/45], Step [200/3663], Loss: 0.2789\n",
      "Epoch [10/45], Step [300/3663], Loss: 0.3068\n",
      "Epoch [10/45], Step [400/3663], Loss: 0.3062\n",
      "Epoch [10/45], Step [500/3663], Loss: 0.2798\n",
      "Epoch [10/45], Step [600/3663], Loss: 0.2571\n",
      "Epoch [10/45], Step [700/3663], Loss: 0.2778\n",
      "Epoch [10/45], Step [800/3663], Loss: 0.2628\n",
      "Epoch [10/45], Step [900/3663], Loss: 0.2628\n",
      "Epoch [10/45], Step [1000/3663], Loss: 0.3332\n",
      "Epoch [10/45], Step [1100/3663], Loss: 0.2767\n",
      "Epoch [10/45], Step [1200/3663], Loss: 0.2731\n",
      "Epoch [10/45], Step [1300/3663], Loss: 0.2603\n",
      "Epoch [10/45], Step [1400/3663], Loss: 0.2643\n",
      "Epoch [10/45], Step [1500/3663], Loss: 0.2782\n",
      "Epoch [10/45], Step [1600/3663], Loss: 0.2930\n",
      "Epoch [10/45], Step [1700/3663], Loss: 0.3034\n",
      "Epoch [10/45], Step [1800/3663], Loss: 0.3071\n",
      "Epoch [10/45], Step [1900/3663], Loss: 0.2786\n",
      "Epoch [10/45], Step [2000/3663], Loss: 0.3058\n",
      "Epoch [10/45], Step [2100/3663], Loss: 0.2801\n",
      "Epoch [10/45], Step [2200/3663], Loss: 0.3104\n",
      "Epoch [10/45], Step [2300/3663], Loss: 0.2811\n",
      "Epoch [10/45], Step [2400/3663], Loss: 0.2923\n",
      "Epoch [10/45], Step [2500/3663], Loss: 0.2788\n",
      "Epoch [10/45], Step [2600/3663], Loss: 0.2478\n",
      "Epoch [10/45], Step [2700/3663], Loss: 0.3004\n",
      "Epoch [10/45], Step [2800/3663], Loss: 0.3143\n",
      "Epoch [10/45], Step [2900/3663], Loss: 0.3069\n",
      "Epoch [10/45], Step [3000/3663], Loss: 0.2844\n",
      "Epoch [10/45], Step [3100/3663], Loss: 0.2788\n",
      "Epoch [10/45], Step [3200/3663], Loss: 0.2844\n",
      "Epoch [10/45], Step [3300/3663], Loss: 0.3053\n",
      "Epoch [10/45], Step [3400/3663], Loss: 0.3271\n",
      "Epoch [10/45], Step [3500/3663], Loss: 0.2717\n",
      "Epoch [10/45], Step [3600/3663], Loss: 0.2990\n",
      "Loss of Epoch 10: 0.2865321861557513\n",
      "Epoch 11 began!\n",
      "Epoch [11/45], Step [100/3663], Loss: 0.2804\n",
      "Epoch [11/45], Step [200/3663], Loss: 0.2600\n",
      "Epoch [11/45], Step [300/3663], Loss: 0.2351\n",
      "Epoch [11/45], Step [400/3663], Loss: 0.3119\n",
      "Epoch [11/45], Step [500/3663], Loss: 0.2531\n",
      "Epoch [11/45], Step [600/3663], Loss: 0.2200\n",
      "Epoch [11/45], Step [700/3663], Loss: 0.2699\n",
      "Epoch [11/45], Step [800/3663], Loss: 0.2854\n",
      "Epoch [11/45], Step [900/3663], Loss: 0.2641\n",
      "Epoch [11/45], Step [1000/3663], Loss: 0.2655\n",
      "Epoch [11/45], Step [1100/3663], Loss: 0.2747\n",
      "Epoch [11/45], Step [1200/3663], Loss: 0.2894\n",
      "Epoch [11/45], Step [1300/3663], Loss: 0.2495\n",
      "Epoch [11/45], Step [1400/3663], Loss: 0.2990\n",
      "Epoch [11/45], Step [1500/3663], Loss: 0.2437\n",
      "Epoch [11/45], Step [1600/3663], Loss: 0.3076\n",
      "Epoch [11/45], Step [1700/3663], Loss: 0.2823\n",
      "Epoch [11/45], Step [1800/3663], Loss: 0.2850\n",
      "Epoch [11/45], Step [1900/3663], Loss: 0.2753\n",
      "Epoch [11/45], Step [2000/3663], Loss: 0.2686\n",
      "Epoch [11/45], Step [2100/3663], Loss: 0.2893\n",
      "Epoch [11/45], Step [2200/3663], Loss: 0.2534\n",
      "Epoch [11/45], Step [2300/3663], Loss: 0.2826\n",
      "Epoch [11/45], Step [2400/3663], Loss: 0.2914\n",
      "Epoch [11/45], Step [2500/3663], Loss: 0.2764\n",
      "Epoch [11/45], Step [2600/3663], Loss: 0.3020\n",
      "Epoch [11/45], Step [2700/3663], Loss: 0.3040\n",
      "Epoch [11/45], Step [2800/3663], Loss: 0.3040\n",
      "Epoch [11/45], Step [2900/3663], Loss: 0.3297\n",
      "Epoch [11/45], Step [3000/3663], Loss: 0.2820\n",
      "Epoch [11/45], Step [3100/3663], Loss: 0.2563\n",
      "Epoch [11/45], Step [3200/3663], Loss: 0.2889\n",
      "Epoch [11/45], Step [3300/3663], Loss: 0.2705\n",
      "Epoch [11/45], Step [3400/3663], Loss: 0.2909\n",
      "Epoch [11/45], Step [3500/3663], Loss: 0.2517\n",
      "Epoch [11/45], Step [3600/3663], Loss: 0.2992\n",
      "Loss of Epoch 11: 0.2779919960862267\n",
      "Epoch 12 began!\n",
      "Epoch [12/45], Step [100/3663], Loss: 0.2813\n",
      "Epoch [12/45], Step [200/3663], Loss: 0.2682\n",
      "Epoch [12/45], Step [300/3663], Loss: 0.2376\n",
      "Epoch [12/45], Step [400/3663], Loss: 0.2603\n",
      "Epoch [12/45], Step [500/3663], Loss: 0.2764\n",
      "Epoch [12/45], Step [600/3663], Loss: 0.2416\n",
      "Epoch [12/45], Step [700/3663], Loss: 0.2548\n",
      "Epoch [12/45], Step [800/3663], Loss: 0.2772\n",
      "Epoch [12/45], Step [900/3663], Loss: 0.2562\n",
      "Epoch [12/45], Step [1000/3663], Loss: 0.2435\n",
      "Epoch [12/45], Step [1100/3663], Loss: 0.2553\n",
      "Epoch [12/45], Step [1200/3663], Loss: 0.3205\n",
      "Epoch [12/45], Step [1300/3663], Loss: 0.2922\n",
      "Epoch [12/45], Step [1400/3663], Loss: 0.2441\n",
      "Epoch [12/45], Step [1500/3663], Loss: 0.2634\n",
      "Epoch [12/45], Step [1600/3663], Loss: 0.2315\n",
      "Epoch [12/45], Step [1700/3663], Loss: 0.3352\n",
      "Epoch [12/45], Step [1800/3663], Loss: 0.2840\n",
      "Epoch [12/45], Step [1900/3663], Loss: 0.2615\n",
      "Epoch [12/45], Step [2000/3663], Loss: 0.2965\n",
      "Epoch [12/45], Step [2100/3663], Loss: 0.2352\n",
      "Epoch [12/45], Step [2200/3663], Loss: 0.2656\n",
      "Epoch [12/45], Step [2300/3663], Loss: 0.2692\n",
      "Epoch [12/45], Step [2400/3663], Loss: 0.2777\n",
      "Epoch [12/45], Step [2500/3663], Loss: 0.2528\n",
      "Epoch [12/45], Step [2600/3663], Loss: 0.2734\n",
      "Epoch [12/45], Step [2700/3663], Loss: 0.2792\n",
      "Epoch [12/45], Step [2800/3663], Loss: 0.2638\n",
      "Epoch [12/45], Step [2900/3663], Loss: 0.2605\n",
      "Epoch [12/45], Step [3000/3663], Loss: 0.3115\n",
      "Epoch [12/45], Step [3100/3663], Loss: 0.2591\n",
      "Epoch [12/45], Step [3200/3663], Loss: 0.2759\n",
      "Epoch [12/45], Step [3300/3663], Loss: 0.2583\n",
      "Epoch [12/45], Step [3400/3663], Loss: 0.2395\n",
      "Epoch [12/45], Step [3500/3663], Loss: 0.2690\n",
      "Epoch [12/45], Step [3600/3663], Loss: 0.3024\n",
      "Loss of Epoch 12: 0.2688615059899204\n",
      "Epoch 13 began!\n",
      "Epoch [13/45], Step [100/3663], Loss: 0.2262\n",
      "Epoch [13/45], Step [200/3663], Loss: 0.2696\n",
      "Epoch [13/45], Step [300/3663], Loss: 0.2341\n",
      "Epoch [13/45], Step [400/3663], Loss: 0.2051\n",
      "Epoch [13/45], Step [500/3663], Loss: 0.2598\n",
      "Epoch [13/45], Step [600/3663], Loss: 0.2044\n",
      "Epoch [13/45], Step [700/3663], Loss: 0.2350\n",
      "Epoch [13/45], Step [800/3663], Loss: 0.2057\n",
      "Epoch [13/45], Step [900/3663], Loss: 0.2840\n",
      "Epoch [13/45], Step [1000/3663], Loss: 0.2427\n",
      "Epoch [13/45], Step [1100/3663], Loss: 0.2916\n",
      "Epoch [13/45], Step [1200/3663], Loss: 0.2757\n",
      "Epoch [13/45], Step [1300/3663], Loss: 0.2509\n",
      "Epoch [13/45], Step [1400/3663], Loss: 0.2502\n",
      "Epoch [13/45], Step [1500/3663], Loss: 0.2774\n",
      "Epoch [13/45], Step [1600/3663], Loss: 0.2594\n",
      "Epoch [13/45], Step [1700/3663], Loss: 0.2565\n",
      "Epoch [13/45], Step [1800/3663], Loss: 0.2855\n",
      "Epoch [13/45], Step [1900/3663], Loss: 0.2559\n",
      "Epoch [13/45], Step [2000/3663], Loss: 0.2798\n",
      "Epoch [13/45], Step [2100/3663], Loss: 0.3021\n",
      "Epoch [13/45], Step [2200/3663], Loss: 0.2835\n",
      "Epoch [13/45], Step [2300/3663], Loss: 0.2958\n",
      "Epoch [13/45], Step [2400/3663], Loss: 0.2298\n",
      "Epoch [13/45], Step [2500/3663], Loss: 0.2477\n",
      "Epoch [13/45], Step [2600/3663], Loss: 0.2727\n",
      "Epoch [13/45], Step [2700/3663], Loss: 0.2730\n",
      "Epoch [13/45], Step [2800/3663], Loss: 0.2664\n",
      "Epoch [13/45], Step [2900/3663], Loss: 0.3101\n",
      "Epoch [13/45], Step [3000/3663], Loss: 0.2283\n",
      "Epoch [13/45], Step [3100/3663], Loss: 0.2738\n",
      "Epoch [13/45], Step [3200/3663], Loss: 0.2779\n",
      "Epoch [13/45], Step [3300/3663], Loss: 0.2891\n",
      "Epoch [13/45], Step [3400/3663], Loss: 0.2743\n",
      "Epoch [13/45], Step [3500/3663], Loss: 0.3059\n",
      "Epoch [13/45], Step [3600/3663], Loss: 0.2497\n",
      "Loss of Epoch 13: 0.2626814925435492\n",
      "Epoch 14 began!\n",
      "Epoch [14/45], Step [100/3663], Loss: 0.2221\n",
      "Epoch [14/45], Step [200/3663], Loss: 0.2103\n",
      "Epoch [14/45], Step [300/3663], Loss: 0.2205\n",
      "Epoch [14/45], Step [400/3663], Loss: 0.2671\n",
      "Epoch [14/45], Step [500/3663], Loss: 0.2425\n",
      "Epoch [14/45], Step [600/3663], Loss: 0.2320\n",
      "Epoch [14/45], Step [700/3663], Loss: 0.2388\n",
      "Epoch [14/45], Step [800/3663], Loss: 0.2275\n",
      "Epoch [14/45], Step [900/3663], Loss: 0.2661\n",
      "Epoch [14/45], Step [1000/3663], Loss: 0.2741\n",
      "Epoch [14/45], Step [1100/3663], Loss: 0.2594\n",
      "Epoch [14/45], Step [1200/3663], Loss: 0.2521\n",
      "Epoch [14/45], Step [1300/3663], Loss: 0.2571\n",
      "Epoch [14/45], Step [1400/3663], Loss: 0.2497\n",
      "Epoch [14/45], Step [1500/3663], Loss: 0.2166\n",
      "Epoch [14/45], Step [1600/3663], Loss: 0.2210\n",
      "Epoch [14/45], Step [1700/3663], Loss: 0.2475\n",
      "Epoch [14/45], Step [1800/3663], Loss: 0.2760\n",
      "Epoch [14/45], Step [1900/3663], Loss: 0.2628\n",
      "Epoch [14/45], Step [2000/3663], Loss: 0.2655\n",
      "Epoch [14/45], Step [2100/3663], Loss: 0.2383\n",
      "Epoch [14/45], Step [2200/3663], Loss: 0.2655\n",
      "Epoch [14/45], Step [2300/3663], Loss: 0.2520\n",
      "Epoch [14/45], Step [2400/3663], Loss: 0.2480\n",
      "Epoch [14/45], Step [2500/3663], Loss: 0.2470\n",
      "Epoch [14/45], Step [2600/3663], Loss: 0.2683\n",
      "Epoch [14/45], Step [2700/3663], Loss: 0.2460\n",
      "Epoch [14/45], Step [2800/3663], Loss: 0.2863\n",
      "Epoch [14/45], Step [2900/3663], Loss: 0.2788\n",
      "Epoch [14/45], Step [3000/3663], Loss: 0.2569\n",
      "Epoch [14/45], Step [3100/3663], Loss: 0.2779\n",
      "Epoch [14/45], Step [3200/3663], Loss: 0.3071\n",
      "Epoch [14/45], Step [3300/3663], Loss: 0.2815\n",
      "Epoch [14/45], Step [3400/3663], Loss: 0.2812\n",
      "Epoch [14/45], Step [3500/3663], Loss: 0.2565\n",
      "Epoch [14/45], Step [3600/3663], Loss: 0.2634\n",
      "Loss of Epoch 14: 0.25484186817108545\n",
      "Epoch 15 began!\n",
      "Epoch [15/45], Step [100/3663], Loss: 0.2406\n",
      "Epoch [15/45], Step [200/3663], Loss: 0.1775\n",
      "Epoch [15/45], Step [300/3663], Loss: 0.1970\n",
      "Epoch [15/45], Step [400/3663], Loss: 0.2074\n",
      "Epoch [15/45], Step [500/3663], Loss: 0.1980\n",
      "Epoch [15/45], Step [600/3663], Loss: 0.2615\n",
      "Epoch [15/45], Step [700/3663], Loss: 0.2152\n",
      "Epoch [15/45], Step [800/3663], Loss: 0.2441\n",
      "Epoch [15/45], Step [900/3663], Loss: 0.2551\n",
      "Epoch [15/45], Step [1000/3663], Loss: 0.2565\n",
      "Epoch [15/45], Step [1100/3663], Loss: 0.2433\n",
      "Epoch [15/45], Step [1200/3663], Loss: 0.2537\n",
      "Epoch [15/45], Step [1300/3663], Loss: 0.2438\n",
      "Epoch [15/45], Step [1400/3663], Loss: 0.2392\n",
      "Epoch [15/45], Step [1500/3663], Loss: 0.2728\n",
      "Epoch [15/45], Step [1600/3663], Loss: 0.2611\n",
      "Epoch [15/45], Step [1700/3663], Loss: 0.2502\n",
      "Epoch [15/45], Step [1800/3663], Loss: 0.2564\n",
      "Epoch [15/45], Step [1900/3663], Loss: 0.2549\n",
      "Epoch [15/45], Step [2000/3663], Loss: 0.2390\n",
      "Epoch [15/45], Step [2100/3663], Loss: 0.2447\n",
      "Epoch [15/45], Step [2200/3663], Loss: 0.2713\n",
      "Epoch [15/45], Step [2300/3663], Loss: 0.2735\n",
      "Epoch [15/45], Step [2400/3663], Loss: 0.2475\n",
      "Epoch [15/45], Step [2500/3663], Loss: 0.2414\n",
      "Epoch [15/45], Step [2600/3663], Loss: 0.2526\n",
      "Epoch [15/45], Step [2700/3663], Loss: 0.2284\n",
      "Epoch [15/45], Step [2800/3663], Loss: 0.2580\n",
      "Epoch [15/45], Step [2900/3663], Loss: 0.2319\n",
      "Epoch [15/45], Step [3000/3663], Loss: 0.2903\n",
      "Epoch [15/45], Step [3100/3663], Loss: 0.2328\n",
      "Epoch [15/45], Step [3200/3663], Loss: 0.2623\n",
      "Epoch [15/45], Step [3300/3663], Loss: 0.2539\n",
      "Epoch [15/45], Step [3400/3663], Loss: 0.3046\n",
      "Epoch [15/45], Step [3500/3663], Loss: 0.2954\n",
      "Epoch [15/45], Step [3600/3663], Loss: 0.2532\n",
      "Loss of Epoch 15: 0.2481335764024951\n",
      "Epoch 16 began!\n",
      "Epoch [16/45], Step [100/3663], Loss: 0.2425\n",
      "Epoch [16/45], Step [200/3663], Loss: 0.2237\n",
      "Epoch [16/45], Step [300/3663], Loss: 0.2363\n",
      "Epoch [16/45], Step [400/3663], Loss: 0.2398\n",
      "Epoch [16/45], Step [500/3663], Loss: 0.1926\n",
      "Epoch [16/45], Step [600/3663], Loss: 0.2297\n",
      "Epoch [16/45], Step [700/3663], Loss: 0.2312\n",
      "Epoch [16/45], Step [800/3663], Loss: 0.2222\n",
      "Epoch [16/45], Step [900/3663], Loss: 0.2646\n",
      "Epoch [16/45], Step [1000/3663], Loss: 0.2217\n",
      "Epoch [16/45], Step [1100/3663], Loss: 0.2079\n",
      "Epoch [16/45], Step [1200/3663], Loss: 0.2276\n",
      "Epoch [16/45], Step [1300/3663], Loss: 0.2995\n",
      "Epoch [16/45], Step [1400/3663], Loss: 0.2457\n",
      "Epoch [16/45], Step [1500/3663], Loss: 0.2168\n",
      "Epoch [16/45], Step [1600/3663], Loss: 0.2148\n",
      "Epoch [16/45], Step [1700/3663], Loss: 0.2148\n",
      "Epoch [16/45], Step [1800/3663], Loss: 0.2320\n",
      "Epoch [16/45], Step [1900/3663], Loss: 0.2353\n",
      "Epoch [16/45], Step [2000/3663], Loss: 0.2799\n",
      "Epoch [16/45], Step [2100/3663], Loss: 0.2336\n",
      "Epoch [16/45], Step [2200/3663], Loss: 0.2837\n",
      "Epoch [16/45], Step [2300/3663], Loss: 0.2555\n",
      "Epoch [16/45], Step [2400/3663], Loss: 0.2333\n",
      "Epoch [16/45], Step [2500/3663], Loss: 0.2822\n",
      "Epoch [16/45], Step [2600/3663], Loss: 0.2542\n",
      "Epoch [16/45], Step [2700/3663], Loss: 0.2575\n",
      "Epoch [16/45], Step [2800/3663], Loss: 0.2731\n",
      "Epoch [16/45], Step [2900/3663], Loss: 0.2502\n",
      "Epoch [16/45], Step [3000/3663], Loss: 0.2346\n",
      "Epoch [16/45], Step [3100/3663], Loss: 0.3059\n",
      "Epoch [16/45], Step [3200/3663], Loss: 0.2198\n",
      "Epoch [16/45], Step [3300/3663], Loss: 0.2463\n",
      "Epoch [16/45], Step [3400/3663], Loss: 0.2645\n",
      "Epoch [16/45], Step [3500/3663], Loss: 0.2580\n",
      "Epoch [16/45], Step [3600/3663], Loss: 0.2731\n",
      "Loss of Epoch 16: 0.24464773951758614\n",
      "Epoch 17 began!\n",
      "Epoch [17/45], Step [100/3663], Loss: 0.2130\n",
      "Epoch [17/45], Step [200/3663], Loss: 0.2253\n",
      "Epoch [17/45], Step [300/3663], Loss: 0.2010\n",
      "Epoch [17/45], Step [400/3663], Loss: 0.2032\n",
      "Epoch [17/45], Step [500/3663], Loss: 0.2269\n",
      "Epoch [17/45], Step [600/3663], Loss: 0.2429\n",
      "Epoch [17/45], Step [700/3663], Loss: 0.2067\n",
      "Epoch [17/45], Step [800/3663], Loss: 0.2326\n",
      "Epoch [17/45], Step [900/3663], Loss: 0.2380\n",
      "Epoch [17/45], Step [1000/3663], Loss: 0.2096\n",
      "Epoch [17/45], Step [1100/3663], Loss: 0.2343\n",
      "Epoch [17/45], Step [1200/3663], Loss: 0.2295\n",
      "Epoch [17/45], Step [1300/3663], Loss: 0.2292\n",
      "Epoch [17/45], Step [1400/3663], Loss: 0.2475\n",
      "Epoch [17/45], Step [1500/3663], Loss: 0.2356\n",
      "Epoch [17/45], Step [1600/3663], Loss: 0.2757\n",
      "Epoch [17/45], Step [1700/3663], Loss: 0.2271\n",
      "Epoch [17/45], Step [1800/3663], Loss: 0.2174\n",
      "Epoch [17/45], Step [1900/3663], Loss: 0.2394\n",
      "Epoch [17/45], Step [2000/3663], Loss: 0.2403\n",
      "Epoch [17/45], Step [2100/3663], Loss: 0.2197\n",
      "Epoch [17/45], Step [2200/3663], Loss: 0.2308\n",
      "Epoch [17/45], Step [2300/3663], Loss: 0.2263\n",
      "Epoch [17/45], Step [2400/3663], Loss: 0.2603\n",
      "Epoch [17/45], Step [2500/3663], Loss: 0.2530\n",
      "Epoch [17/45], Step [2600/3663], Loss: 0.2177\n",
      "Epoch [17/45], Step [2700/3663], Loss: 0.2800\n",
      "Epoch [17/45], Step [2800/3663], Loss: 0.2366\n",
      "Epoch [17/45], Step [2900/3663], Loss: 0.2643\n",
      "Epoch [17/45], Step [3000/3663], Loss: 0.2315\n",
      "Epoch [17/45], Step [3100/3663], Loss: 0.2757\n",
      "Epoch [17/45], Step [3200/3663], Loss: 0.2500\n",
      "Epoch [17/45], Step [3300/3663], Loss: 0.2479\n",
      "Epoch [17/45], Step [3400/3663], Loss: 0.2494\n",
      "Epoch [17/45], Step [3500/3663], Loss: 0.2455\n",
      "Epoch [17/45], Step [3600/3663], Loss: 0.2109\n",
      "Loss of Epoch 17: 0.23582702885409082\n",
      "Epoch 18 began!\n",
      "Epoch [18/45], Step [100/3663], Loss: 0.2134\n",
      "Epoch [18/45], Step [200/3663], Loss: 0.2237\n",
      "Epoch [18/45], Step [300/3663], Loss: 0.2006\n",
      "Epoch [18/45], Step [400/3663], Loss: 0.2272\n",
      "Epoch [18/45], Step [500/3663], Loss: 0.2028\n",
      "Epoch [18/45], Step [600/3663], Loss: 0.2164\n",
      "Epoch [18/45], Step [700/3663], Loss: 0.1943\n",
      "Epoch [18/45], Step [800/3663], Loss: 0.2213\n",
      "Epoch [18/45], Step [900/3663], Loss: 0.2045\n",
      "Epoch [18/45], Step [1000/3663], Loss: 0.2553\n",
      "Epoch [18/45], Step [1100/3663], Loss: 0.2464\n",
      "Epoch [18/45], Step [1200/3663], Loss: 0.2113\n",
      "Epoch [18/45], Step [1300/3663], Loss: 0.2293\n",
      "Epoch [18/45], Step [1400/3663], Loss: 0.2556\n",
      "Epoch [18/45], Step [1500/3663], Loss: 0.2434\n",
      "Epoch [18/45], Step [1600/3663], Loss: 0.2492\n",
      "Epoch [18/45], Step [1700/3663], Loss: 0.2261\n",
      "Epoch [18/45], Step [1800/3663], Loss: 0.2676\n",
      "Epoch [18/45], Step [1900/3663], Loss: 0.2251\n",
      "Epoch [18/45], Step [2000/3663], Loss: 0.2329\n",
      "Epoch [18/45], Step [2100/3663], Loss: 0.2394\n",
      "Epoch [18/45], Step [2200/3663], Loss: 0.2382\n",
      "Epoch [18/45], Step [2300/3663], Loss: 0.2627\n",
      "Epoch [18/45], Step [2400/3663], Loss: 0.2381\n",
      "Epoch [18/45], Step [2500/3663], Loss: 0.2441\n",
      "Epoch [18/45], Step [2600/3663], Loss: 0.2185\n",
      "Epoch [18/45], Step [2700/3663], Loss: 0.2301\n",
      "Epoch [18/45], Step [2800/3663], Loss: 0.2639\n",
      "Epoch [18/45], Step [2900/3663], Loss: 0.2461\n",
      "Epoch [18/45], Step [3000/3663], Loss: 0.2388\n",
      "Epoch [18/45], Step [3100/3663], Loss: 0.2279\n",
      "Epoch [18/45], Step [3200/3663], Loss: 0.2468\n",
      "Epoch [18/45], Step [3300/3663], Loss: 0.2639\n",
      "Epoch [18/45], Step [3400/3663], Loss: 0.2593\n",
      "Epoch [18/45], Step [3500/3663], Loss: 0.2603\n",
      "Epoch [18/45], Step [3600/3663], Loss: 0.2248\n",
      "Loss of Epoch 18: 0.23422572314348952\n",
      "Epoch 19 began!\n",
      "Epoch [19/45], Step [100/3663], Loss: 0.1878\n",
      "Epoch [19/45], Step [200/3663], Loss: 0.2346\n",
      "Epoch [19/45], Step [300/3663], Loss: 0.2165\n",
      "Epoch [19/45], Step [400/3663], Loss: 0.2163\n",
      "Epoch [19/45], Step [500/3663], Loss: 0.2027\n",
      "Epoch [19/45], Step [600/3663], Loss: 0.2101\n",
      "Epoch [19/45], Step [700/3663], Loss: 0.2000\n",
      "Epoch [19/45], Step [800/3663], Loss: 0.2510\n",
      "Epoch [19/45], Step [900/3663], Loss: 0.2312\n",
      "Epoch [19/45], Step [1000/3663], Loss: 0.1977\n",
      "Epoch [19/45], Step [1100/3663], Loss: 0.2265\n",
      "Epoch [19/45], Step [1200/3663], Loss: 0.2378\n",
      "Epoch [19/45], Step [1300/3663], Loss: 0.2306\n",
      "Epoch [19/45], Step [1400/3663], Loss: 0.2226\n",
      "Epoch [19/45], Step [1500/3663], Loss: 0.2268\n",
      "Epoch [19/45], Step [1600/3663], Loss: 0.2282\n",
      "Epoch [19/45], Step [1700/3663], Loss: 0.2210\n",
      "Epoch [19/45], Step [1800/3663], Loss: 0.2583\n",
      "Epoch [19/45], Step [1900/3663], Loss: 0.2357\n",
      "Epoch [19/45], Step [2000/3663], Loss: 0.2339\n",
      "Epoch [19/45], Step [2100/3663], Loss: 0.2500\n",
      "Epoch [19/45], Step [2200/3663], Loss: 0.2542\n",
      "Epoch [19/45], Step [2300/3663], Loss: 0.2344\n",
      "Epoch [19/45], Step [2400/3663], Loss: 0.2106\n",
      "Epoch [19/45], Step [2500/3663], Loss: 0.2011\n",
      "Epoch [19/45], Step [2600/3663], Loss: 0.2495\n",
      "Epoch [19/45], Step [2700/3663], Loss: 0.2193\n",
      "Epoch [19/45], Step [2800/3663], Loss: 0.2582\n",
      "Epoch [19/45], Step [2900/3663], Loss: 0.2010\n",
      "Epoch [19/45], Step [3000/3663], Loss: 0.2478\n",
      "Epoch [19/45], Step [3100/3663], Loss: 0.2438\n",
      "Epoch [19/45], Step [3200/3663], Loss: 0.2640\n",
      "Epoch [19/45], Step [3300/3663], Loss: 0.2450\n",
      "Epoch [19/45], Step [3400/3663], Loss: 0.2054\n",
      "Epoch [19/45], Step [3500/3663], Loss: 0.2608\n",
      "Epoch [19/45], Step [3600/3663], Loss: 0.2232\n",
      "Loss of Epoch 19: 0.2293363412781579\n",
      "Epoch 20 began!\n",
      "Epoch [20/45], Step [100/3663], Loss: 0.1764\n",
      "Epoch [20/45], Step [200/3663], Loss: 0.1987\n",
      "Epoch [20/45], Step [300/3663], Loss: 0.1888\n",
      "Epoch [20/45], Step [400/3663], Loss: 0.2202\n",
      "Epoch [20/45], Step [500/3663], Loss: 0.2317\n",
      "Epoch [20/45], Step [600/3663], Loss: 0.1856\n",
      "Epoch [20/45], Step [700/3663], Loss: 0.2014\n",
      "Epoch [20/45], Step [800/3663], Loss: 0.2329\n",
      "Epoch [20/45], Step [900/3663], Loss: 0.2152\n",
      "Epoch [20/45], Step [1000/3663], Loss: 0.1929\n",
      "Epoch [20/45], Step [1100/3663], Loss: 0.2495\n",
      "Epoch [20/45], Step [1200/3663], Loss: 0.2020\n",
      "Epoch [20/45], Step [1300/3663], Loss: 0.2166\n",
      "Epoch [20/45], Step [1400/3663], Loss: 0.2104\n",
      "Epoch [20/45], Step [1500/3663], Loss: 0.2315\n",
      "Epoch [20/45], Step [1600/3663], Loss: 0.2426\n",
      "Epoch [20/45], Step [1700/3663], Loss: 0.2381\n",
      "Epoch [20/45], Step [1800/3663], Loss: 0.2418\n",
      "Epoch [20/45], Step [1900/3663], Loss: 0.2444\n",
      "Epoch [20/45], Step [2000/3663], Loss: 0.2284\n",
      "Epoch [20/45], Step [2100/3663], Loss: 0.2333\n",
      "Epoch [20/45], Step [2200/3663], Loss: 0.2372\n",
      "Epoch [20/45], Step [2300/3663], Loss: 0.2224\n",
      "Epoch [20/45], Step [2400/3663], Loss: 0.2555\n",
      "Epoch [20/45], Step [2500/3663], Loss: 0.2236\n",
      "Epoch [20/45], Step [2600/3663], Loss: 0.2621\n",
      "Epoch [20/45], Step [2700/3663], Loss: 0.2417\n",
      "Epoch [20/45], Step [2800/3663], Loss: 0.2124\n",
      "Epoch [20/45], Step [2900/3663], Loss: 0.2590\n",
      "Epoch [20/45], Step [3000/3663], Loss: 0.2368\n",
      "Epoch [20/45], Step [3100/3663], Loss: 0.2050\n",
      "Epoch [20/45], Step [3200/3663], Loss: 0.2110\n",
      "Epoch [20/45], Step [3300/3663], Loss: 0.2699\n",
      "Epoch [20/45], Step [3400/3663], Loss: 0.2443\n",
      "Epoch [20/45], Step [3500/3663], Loss: 0.2129\n",
      "Epoch [20/45], Step [3600/3663], Loss: 0.2193\n",
      "Loss of Epoch 20: 0.2251630801058657\n",
      "Epoch 21 began!\n",
      "Epoch [21/45], Step [100/3663], Loss: 0.2057\n",
      "Epoch [21/45], Step [200/3663], Loss: 0.1940\n",
      "Epoch [21/45], Step [300/3663], Loss: 0.1974\n",
      "Epoch [21/45], Step [400/3663], Loss: 0.2238\n",
      "Epoch [21/45], Step [500/3663], Loss: 0.1912\n",
      "Epoch [21/45], Step [600/3663], Loss: 0.2252\n",
      "Epoch [21/45], Step [700/3663], Loss: 0.1800\n",
      "Epoch [21/45], Step [800/3663], Loss: 0.1869\n",
      "Epoch [21/45], Step [900/3663], Loss: 0.2356\n",
      "Epoch [21/45], Step [1000/3663], Loss: 0.2534\n",
      "Epoch [21/45], Step [1100/3663], Loss: 0.1974\n",
      "Epoch [21/45], Step [1200/3663], Loss: 0.2135\n",
      "Epoch [21/45], Step [1300/3663], Loss: 0.2446\n",
      "Epoch [21/45], Step [1400/3663], Loss: 0.1944\n",
      "Epoch [21/45], Step [1500/3663], Loss: 0.2183\n",
      "Epoch [21/45], Step [1600/3663], Loss: 0.2293\n",
      "Epoch [21/45], Step [1700/3663], Loss: 0.2208\n",
      "Epoch [21/45], Step [1800/3663], Loss: 0.2238\n",
      "Epoch [21/45], Step [1900/3663], Loss: 0.2190\n",
      "Epoch [21/45], Step [2000/3663], Loss: 0.2350\n",
      "Epoch [21/45], Step [2100/3663], Loss: 0.2535\n",
      "Epoch [21/45], Step [2200/3663], Loss: 0.2536\n",
      "Epoch [21/45], Step [2300/3663], Loss: 0.2556\n",
      "Epoch [21/45], Step [2400/3663], Loss: 0.2358\n",
      "Epoch [21/45], Step [2500/3663], Loss: 0.2472\n",
      "Epoch [21/45], Step [2600/3663], Loss: 0.2114\n",
      "Epoch [21/45], Step [2700/3663], Loss: 0.2261\n",
      "Epoch [21/45], Step [2800/3663], Loss: 0.1841\n",
      "Epoch [21/45], Step [2900/3663], Loss: 0.1709\n",
      "Epoch [21/45], Step [3000/3663], Loss: 0.2182\n",
      "Epoch [21/45], Step [3100/3663], Loss: 0.2608\n",
      "Epoch [21/45], Step [3200/3663], Loss: 0.2417\n",
      "Epoch [21/45], Step [3300/3663], Loss: 0.2532\n",
      "Epoch [21/45], Step [3400/3663], Loss: 0.2308\n",
      "Epoch [21/45], Step [3500/3663], Loss: 0.2180\n",
      "Epoch [21/45], Step [3600/3663], Loss: 0.2265\n",
      "Loss of Epoch 21: 0.22240478955146964\n",
      "Epoch 22 began!\n",
      "Epoch [22/45], Step [100/3663], Loss: 0.1915\n",
      "Epoch [22/45], Step [200/3663], Loss: 0.1747\n",
      "Epoch [22/45], Step [300/3663], Loss: 0.1698\n",
      "Epoch [22/45], Step [400/3663], Loss: 0.1933\n",
      "Epoch [22/45], Step [500/3663], Loss: 0.1910\n",
      "Epoch [22/45], Step [600/3663], Loss: 0.2349\n",
      "Epoch [22/45], Step [700/3663], Loss: 0.1833\n",
      "Epoch [22/45], Step [800/3663], Loss: 0.2062\n",
      "Epoch [22/45], Step [900/3663], Loss: 0.2112\n",
      "Epoch [22/45], Step [1000/3663], Loss: 0.1906\n",
      "Epoch [22/45], Step [1100/3663], Loss: 0.1954\n",
      "Epoch [22/45], Step [1200/3663], Loss: 0.2125\n",
      "Epoch [22/45], Step [1300/3663], Loss: 0.2244\n",
      "Epoch [22/45], Step [1400/3663], Loss: 0.2189\n",
      "Epoch [22/45], Step [1500/3663], Loss: 0.2327\n",
      "Epoch [22/45], Step [1600/3663], Loss: 0.2373\n",
      "Epoch [22/45], Step [1700/3663], Loss: 0.2327\n",
      "Epoch [22/45], Step [1800/3663], Loss: 0.2409\n",
      "Epoch [22/45], Step [1900/3663], Loss: 0.2359\n",
      "Epoch [22/45], Step [2000/3663], Loss: 0.2438\n",
      "Epoch [22/45], Step [2100/3663], Loss: 0.2437\n",
      "Epoch [22/45], Step [2200/3663], Loss: 0.2236\n",
      "Epoch [22/45], Step [2300/3663], Loss: 0.2192\n",
      "Epoch [22/45], Step [2400/3663], Loss: 0.2157\n",
      "Epoch [22/45], Step [2500/3663], Loss: 0.2273\n",
      "Epoch [22/45], Step [2600/3663], Loss: 0.2046\n",
      "Epoch [22/45], Step [2700/3663], Loss: 0.2271\n",
      "Epoch [22/45], Step [2800/3663], Loss: 0.2095\n",
      "Epoch [22/45], Step [2900/3663], Loss: 0.2154\n",
      "Epoch [22/45], Step [3000/3663], Loss: 0.2472\n",
      "Epoch [22/45], Step [3100/3663], Loss: 0.2276\n",
      "Epoch [22/45], Step [3200/3663], Loss: 0.2326\n",
      "Epoch [22/45], Step [3300/3663], Loss: 0.2633\n",
      "Epoch [22/45], Step [3400/3663], Loss: 0.2332\n",
      "Epoch [22/45], Step [3500/3663], Loss: 0.2663\n",
      "Epoch [22/45], Step [3600/3663], Loss: 0.2204\n",
      "Loss of Epoch 22: 0.21963216159180637\n",
      "Epoch 23 began!\n",
      "Epoch [23/45], Step [100/3663], Loss: 0.2066\n",
      "Epoch [23/45], Step [200/3663], Loss: 0.1712\n",
      "Epoch [23/45], Step [300/3663], Loss: 0.2175\n",
      "Epoch [23/45], Step [400/3663], Loss: 0.2187\n",
      "Epoch [23/45], Step [500/3663], Loss: 0.1963\n",
      "Epoch [23/45], Step [600/3663], Loss: 0.2081\n",
      "Epoch [23/45], Step [700/3663], Loss: 0.1893\n",
      "Epoch [23/45], Step [800/3663], Loss: 0.1735\n",
      "Epoch [23/45], Step [900/3663], Loss: 0.2092\n",
      "Epoch [23/45], Step [1000/3663], Loss: 0.2311\n",
      "Epoch [23/45], Step [1100/3663], Loss: 0.1959\n",
      "Epoch [23/45], Step [1200/3663], Loss: 0.2106\n",
      "Epoch [23/45], Step [1300/3663], Loss: 0.2111\n",
      "Epoch [23/45], Step [1400/3663], Loss: 0.2261\n",
      "Epoch [23/45], Step [1500/3663], Loss: 0.1837\n",
      "Epoch [23/45], Step [1600/3663], Loss: 0.1919\n",
      "Epoch [23/45], Step [1700/3663], Loss: 0.2516\n",
      "Epoch [23/45], Step [1800/3663], Loss: 0.1698\n",
      "Epoch [23/45], Step [1900/3663], Loss: 0.2433\n",
      "Epoch [23/45], Step [2000/3663], Loss: 0.1957\n",
      "Epoch [23/45], Step [2100/3663], Loss: 0.2098\n",
      "Epoch [23/45], Step [2200/3663], Loss: 0.2346\n",
      "Epoch [23/45], Step [2300/3663], Loss: 0.2237\n",
      "Epoch [23/45], Step [2400/3663], Loss: 0.2355\n",
      "Epoch [23/45], Step [2500/3663], Loss: 0.2294\n",
      "Epoch [23/45], Step [2600/3663], Loss: 0.2368\n",
      "Epoch [23/45], Step [2700/3663], Loss: 0.2596\n",
      "Epoch [23/45], Step [2800/3663], Loss: 0.2090\n",
      "Epoch [23/45], Step [2900/3663], Loss: 0.2306\n",
      "Epoch [23/45], Step [3000/3663], Loss: 0.2023\n",
      "Epoch [23/45], Step [3100/3663], Loss: 0.2347\n",
      "Epoch [23/45], Step [3200/3663], Loss: 0.2246\n",
      "Epoch [23/45], Step [3300/3663], Loss: 0.2131\n",
      "Epoch [23/45], Step [3400/3663], Loss: 0.2641\n",
      "Epoch [23/45], Step [3500/3663], Loss: 0.2221\n",
      "Epoch [23/45], Step [3600/3663], Loss: 0.2476\n",
      "Loss of Epoch 23: 0.2163382675240659\n",
      "Epoch 24 began!\n",
      "Epoch [24/45], Step [100/3663], Loss: 0.1726\n",
      "Epoch [24/45], Step [200/3663], Loss: 0.1888\n",
      "Epoch [24/45], Step [300/3663], Loss: 0.1625\n",
      "Epoch [24/45], Step [400/3663], Loss: 0.2168\n",
      "Epoch [24/45], Step [500/3663], Loss: 0.2087\n",
      "Epoch [24/45], Step [600/3663], Loss: 0.1857\n",
      "Epoch [24/45], Step [700/3663], Loss: 0.1989\n",
      "Epoch [24/45], Step [800/3663], Loss: 0.1835\n",
      "Epoch [24/45], Step [900/3663], Loss: 0.2084\n",
      "Epoch [24/45], Step [1000/3663], Loss: 0.2196\n",
      "Epoch [24/45], Step [1100/3663], Loss: 0.2316\n",
      "Epoch [24/45], Step [1200/3663], Loss: 0.2085\n",
      "Epoch [24/45], Step [1300/3663], Loss: 0.2343\n",
      "Epoch [24/45], Step [1400/3663], Loss: 0.1997\n",
      "Epoch [24/45], Step [1500/3663], Loss: 0.2217\n",
      "Epoch [24/45], Step [1600/3663], Loss: 0.2053\n",
      "Epoch [24/45], Step [1700/3663], Loss: 0.2050\n",
      "Epoch [24/45], Step [1800/3663], Loss: 0.2446\n",
      "Epoch [24/45], Step [1900/3663], Loss: 0.1957\n",
      "Epoch [24/45], Step [2000/3663], Loss: 0.2070\n",
      "Epoch [24/45], Step [2100/3663], Loss: 0.2122\n",
      "Epoch [24/45], Step [2200/3663], Loss: 0.1974\n",
      "Epoch [24/45], Step [2300/3663], Loss: 0.1780\n",
      "Epoch [24/45], Step [2400/3663], Loss: 0.1897\n",
      "Epoch [24/45], Step [2500/3663], Loss: 0.1984\n",
      "Epoch [24/45], Step [2600/3663], Loss: 0.2453\n",
      "Epoch [24/45], Step [2700/3663], Loss: 0.2340\n",
      "Epoch [24/45], Step [2800/3663], Loss: 0.2312\n",
      "Epoch [24/45], Step [2900/3663], Loss: 0.2241\n",
      "Epoch [24/45], Step [3000/3663], Loss: 0.2266\n",
      "Epoch [24/45], Step [3100/3663], Loss: 0.2109\n",
      "Epoch [24/45], Step [3200/3663], Loss: 0.2087\n",
      "Epoch [24/45], Step [3300/3663], Loss: 0.2219\n",
      "Epoch [24/45], Step [3400/3663], Loss: 0.2299\n",
      "Epoch [24/45], Step [3500/3663], Loss: 0.2371\n",
      "Epoch [24/45], Step [3600/3663], Loss: 0.2343\n",
      "Loss of Epoch 24: 0.21099666262612737\n",
      "Epoch 25 began!\n",
      "Epoch [25/45], Step [100/3663], Loss: 0.1714\n",
      "Epoch [25/45], Step [200/3663], Loss: 0.1947\n",
      "Epoch [25/45], Step [300/3663], Loss: 0.1844\n",
      "Epoch [25/45], Step [400/3663], Loss: 0.1926\n",
      "Epoch [25/45], Step [500/3663], Loss: 0.1983\n",
      "Epoch [25/45], Step [600/3663], Loss: 0.2059\n",
      "Epoch [25/45], Step [700/3663], Loss: 0.1916\n",
      "Epoch [25/45], Step [800/3663], Loss: 0.1954\n",
      "Epoch [25/45], Step [900/3663], Loss: 0.1857\n",
      "Epoch [25/45], Step [1000/3663], Loss: 0.1844\n",
      "Epoch [25/45], Step [1100/3663], Loss: 0.1964\n",
      "Epoch [25/45], Step [1200/3663], Loss: 0.1968\n",
      "Epoch [25/45], Step [1300/3663], Loss: 0.2020\n",
      "Epoch [25/45], Step [1400/3663], Loss: 0.2477\n",
      "Epoch [25/45], Step [1500/3663], Loss: 0.2119\n",
      "Epoch [25/45], Step [1600/3663], Loss: 0.1872\n",
      "Epoch [25/45], Step [1700/3663], Loss: 0.2109\n",
      "Epoch [25/45], Step [1800/3663], Loss: 0.2024\n",
      "Epoch [25/45], Step [1900/3663], Loss: 0.1914\n",
      "Epoch [25/45], Step [2000/3663], Loss: 0.2078\n",
      "Epoch [25/45], Step [2100/3663], Loss: 0.2245\n",
      "Epoch [25/45], Step [2200/3663], Loss: 0.1966\n",
      "Epoch [25/45], Step [2300/3663], Loss: 0.1832\n",
      "Epoch [25/45], Step [2400/3663], Loss: 0.2253\n",
      "Epoch [25/45], Step [2500/3663], Loss: 0.2110\n",
      "Epoch [25/45], Step [2600/3663], Loss: 0.2352\n",
      "Epoch [25/45], Step [2700/3663], Loss: 0.2279\n",
      "Epoch [25/45], Step [2800/3663], Loss: 0.2422\n",
      "Epoch [25/45], Step [2900/3663], Loss: 0.2257\n",
      "Epoch [25/45], Step [3000/3663], Loss: 0.2556\n",
      "Epoch [25/45], Step [3100/3663], Loss: 0.2068\n",
      "Epoch [25/45], Step [3200/3663], Loss: 0.2419\n",
      "Epoch [25/45], Step [3300/3663], Loss: 0.2045\n",
      "Epoch [25/45], Step [3400/3663], Loss: 0.2006\n",
      "Epoch [25/45], Step [3500/3663], Loss: 0.2445\n",
      "Epoch [25/45], Step [3600/3663], Loss: 0.2235\n",
      "Loss of Epoch 25: 0.20879647940942123\n",
      "Epoch 26 began!\n",
      "Epoch [26/45], Step [100/3663], Loss: 0.1841\n",
      "Epoch [26/45], Step [200/3663], Loss: 0.2152\n",
      "Epoch [26/45], Step [300/3663], Loss: 0.1774\n",
      "Epoch [26/45], Step [400/3663], Loss: 0.1913\n",
      "Epoch [26/45], Step [500/3663], Loss: 0.1947\n",
      "Epoch [26/45], Step [600/3663], Loss: 0.1845\n",
      "Epoch [26/45], Step [700/3663], Loss: 0.1554\n",
      "Epoch [26/45], Step [800/3663], Loss: 0.2135\n",
      "Epoch [26/45], Step [900/3663], Loss: 0.1805\n",
      "Epoch [26/45], Step [1000/3663], Loss: 0.1805\n",
      "Epoch [26/45], Step [1100/3663], Loss: 0.2015\n",
      "Epoch [26/45], Step [1200/3663], Loss: 0.2425\n",
      "Epoch [26/45], Step [1300/3663], Loss: 0.2019\n",
      "Epoch [26/45], Step [1400/3663], Loss: 0.2087\n",
      "Epoch [26/45], Step [1500/3663], Loss: 0.1746\n",
      "Epoch [26/45], Step [1600/3663], Loss: 0.2331\n",
      "Epoch [26/45], Step [1700/3663], Loss: 0.2047\n",
      "Epoch [26/45], Step [1800/3663], Loss: 0.2242\n",
      "Epoch [26/45], Step [1900/3663], Loss: 0.2557\n",
      "Epoch [26/45], Step [2000/3663], Loss: 0.2281\n",
      "Epoch [26/45], Step [2100/3663], Loss: 0.2007\n",
      "Epoch [26/45], Step [2200/3663], Loss: 0.2250\n",
      "Epoch [26/45], Step [2300/3663], Loss: 0.1916\n",
      "Epoch [26/45], Step [2400/3663], Loss: 0.1823\n",
      "Epoch [26/45], Step [2500/3663], Loss: 0.1939\n",
      "Epoch [26/45], Step [2600/3663], Loss: 0.2077\n",
      "Epoch [26/45], Step [2700/3663], Loss: 0.2275\n",
      "Epoch [26/45], Step [2800/3663], Loss: 0.2148\n",
      "Epoch [26/45], Step [2900/3663], Loss: 0.1971\n",
      "Epoch [26/45], Step [3000/3663], Loss: 0.2362\n",
      "Epoch [26/45], Step [3100/3663], Loss: 0.2316\n",
      "Epoch [26/45], Step [3200/3663], Loss: 0.1861\n",
      "Epoch [26/45], Step [3300/3663], Loss: 0.1798\n",
      "Epoch [26/45], Step [3400/3663], Loss: 0.2042\n",
      "Epoch [26/45], Step [3500/3663], Loss: 0.2056\n",
      "Epoch [26/45], Step [3600/3663], Loss: 0.1965\n",
      "Loss of Epoch 26: 0.2032930811822878\n",
      "Epoch 27 began!\n",
      "Epoch [27/45], Step [100/3663], Loss: 0.2100\n",
      "Epoch [27/45], Step [200/3663], Loss: 0.1917\n",
      "Epoch [27/45], Step [300/3663], Loss: 0.1607\n",
      "Epoch [27/45], Step [400/3663], Loss: 0.2013\n",
      "Epoch [27/45], Step [500/3663], Loss: 0.1975\n",
      "Epoch [27/45], Step [600/3663], Loss: 0.2190\n",
      "Epoch [27/45], Step [700/3663], Loss: 0.2177\n",
      "Epoch [27/45], Step [800/3663], Loss: 0.1993\n",
      "Epoch [27/45], Step [900/3663], Loss: 0.1463\n",
      "Epoch [27/45], Step [1000/3663], Loss: 0.1953\n",
      "Epoch [27/45], Step [1100/3663], Loss: 0.1645\n",
      "Epoch [27/45], Step [1200/3663], Loss: 0.1768\n",
      "Epoch [27/45], Step [1300/3663], Loss: 0.2186\n",
      "Epoch [27/45], Step [1400/3663], Loss: 0.1958\n",
      "Epoch [27/45], Step [1500/3663], Loss: 0.1910\n",
      "Epoch [27/45], Step [1600/3663], Loss: 0.2350\n",
      "Epoch [27/45], Step [1700/3663], Loss: 0.1968\n",
      "Epoch [27/45], Step [1800/3663], Loss: 0.1980\n",
      "Epoch [27/45], Step [1900/3663], Loss: 0.1837\n",
      "Epoch [27/45], Step [2000/3663], Loss: 0.1963\n",
      "Epoch [27/45], Step [2100/3663], Loss: 0.2324\n",
      "Epoch [27/45], Step [2200/3663], Loss: 0.1954\n",
      "Epoch [27/45], Step [2300/3663], Loss: 0.1879\n",
      "Epoch [27/45], Step [2400/3663], Loss: 0.2033\n",
      "Epoch [27/45], Step [2500/3663], Loss: 0.2027\n",
      "Epoch [27/45], Step [2600/3663], Loss: 0.2035\n",
      "Epoch [27/45], Step [2700/3663], Loss: 0.1982\n",
      "Epoch [27/45], Step [2800/3663], Loss: 0.2016\n",
      "Epoch [27/45], Step [2900/3663], Loss: 0.2370\n",
      "Epoch [27/45], Step [3000/3663], Loss: 0.1850\n",
      "Epoch [27/45], Step [3100/3663], Loss: 0.2252\n",
      "Epoch [27/45], Step [3200/3663], Loss: 0.2010\n",
      "Epoch [27/45], Step [3300/3663], Loss: 0.2227\n",
      "Epoch [27/45], Step [3400/3663], Loss: 0.2273\n",
      "Epoch [27/45], Step [3500/3663], Loss: 0.2142\n",
      "Epoch [27/45], Step [3600/3663], Loss: 0.2681\n",
      "Loss of Epoch 27: 0.20359037162170604\n",
      "Epoch 28 began!\n",
      "Epoch [28/45], Step [100/3663], Loss: 0.1700\n",
      "Epoch [28/45], Step [200/3663], Loss: 0.1620\n",
      "Epoch [28/45], Step [300/3663], Loss: 0.1547\n",
      "Epoch [28/45], Step [400/3663], Loss: 0.1788\n",
      "Epoch [28/45], Step [500/3663], Loss: 0.2035\n",
      "Epoch [28/45], Step [600/3663], Loss: 0.2161\n",
      "Epoch [28/45], Step [700/3663], Loss: 0.1915\n",
      "Epoch [28/45], Step [800/3663], Loss: 0.1597\n",
      "Epoch [28/45], Step [900/3663], Loss: 0.1544\n",
      "Epoch [28/45], Step [1000/3663], Loss: 0.2162\n",
      "Epoch [28/45], Step [1100/3663], Loss: 0.2095\n",
      "Epoch [28/45], Step [1200/3663], Loss: 0.1778\n",
      "Epoch [28/45], Step [1300/3663], Loss: 0.1718\n",
      "Epoch [28/45], Step [1400/3663], Loss: 0.2300\n",
      "Epoch [28/45], Step [1500/3663], Loss: 0.1415\n",
      "Epoch [28/45], Step [1600/3663], Loss: 0.2028\n",
      "Epoch [28/45], Step [1700/3663], Loss: 0.2432\n",
      "Epoch [28/45], Step [1800/3663], Loss: 0.1972\n",
      "Epoch [28/45], Step [1900/3663], Loss: 0.1889\n",
      "Epoch [28/45], Step [2000/3663], Loss: 0.2327\n",
      "Epoch [28/45], Step [2100/3663], Loss: 0.2443\n",
      "Epoch [28/45], Step [2200/3663], Loss: 0.2041\n",
      "Epoch [28/45], Step [2300/3663], Loss: 0.1807\n",
      "Epoch [28/45], Step [2400/3663], Loss: 0.2111\n",
      "Epoch [28/45], Step [2500/3663], Loss: 0.2296\n",
      "Epoch [28/45], Step [2600/3663], Loss: 0.1840\n",
      "Epoch [28/45], Step [2700/3663], Loss: 0.2289\n",
      "Epoch [28/45], Step [2800/3663], Loss: 0.1865\n",
      "Epoch [28/45], Step [2900/3663], Loss: 0.2266\n",
      "Epoch [28/45], Step [3000/3663], Loss: 0.2069\n",
      "Epoch [28/45], Step [3100/3663], Loss: 0.1726\n",
      "Epoch [28/45], Step [3200/3663], Loss: 0.2232\n",
      "Epoch [28/45], Step [3300/3663], Loss: 0.2160\n",
      "Epoch [28/45], Step [3400/3663], Loss: 0.2169\n",
      "Epoch [28/45], Step [3500/3663], Loss: 0.1915\n",
      "Epoch [28/45], Step [3600/3663], Loss: 0.2261\n",
      "Loss of Epoch 28: 0.19960950826263066\n",
      "Epoch 29 began!\n",
      "Epoch [29/45], Step [100/3663], Loss: 0.1636\n",
      "Epoch [29/45], Step [200/3663], Loss: 0.1751\n",
      "Epoch [29/45], Step [300/3663], Loss: 0.1732\n",
      "Epoch [29/45], Step [400/3663], Loss: 0.1902\n",
      "Epoch [29/45], Step [500/3663], Loss: 0.1938\n",
      "Epoch [29/45], Step [600/3663], Loss: 0.1356\n",
      "Epoch [29/45], Step [700/3663], Loss: 0.1848\n",
      "Epoch [29/45], Step [800/3663], Loss: 0.2169\n",
      "Epoch [29/45], Step [900/3663], Loss: 0.1608\n",
      "Epoch [29/45], Step [1000/3663], Loss: 0.1673\n",
      "Epoch [29/45], Step [1100/3663], Loss: 0.2199\n",
      "Epoch [29/45], Step [1200/3663], Loss: 0.1983\n",
      "Epoch [29/45], Step [1300/3663], Loss: 0.1803\n",
      "Epoch [29/45], Step [1400/3663], Loss: 0.1642\n",
      "Epoch [29/45], Step [1500/3663], Loss: 0.1882\n",
      "Epoch [29/45], Step [1600/3663], Loss: 0.2182\n",
      "Epoch [29/45], Step [1700/3663], Loss: 0.1993\n",
      "Epoch [29/45], Step [1800/3663], Loss: 0.1860\n",
      "Epoch [29/45], Step [1900/3663], Loss: 0.1908\n",
      "Epoch [29/45], Step [2000/3663], Loss: 0.2163\n",
      "Epoch [29/45], Step [2100/3663], Loss: 0.2351\n",
      "Epoch [29/45], Step [2200/3663], Loss: 0.1876\n",
      "Epoch [29/45], Step [2300/3663], Loss: 0.1826\n",
      "Epoch [29/45], Step [2400/3663], Loss: 0.2127\n",
      "Epoch [29/45], Step [2500/3663], Loss: 0.1810\n",
      "Epoch [29/45], Step [2600/3663], Loss: 0.2212\n",
      "Epoch [29/45], Step [2700/3663], Loss: 0.2185\n",
      "Epoch [29/45], Step [2800/3663], Loss: 0.2511\n",
      "Epoch [29/45], Step [2900/3663], Loss: 0.2618\n",
      "Epoch [29/45], Step [3000/3663], Loss: 0.1908\n",
      "Epoch [29/45], Step [3100/3663], Loss: 0.1988\n",
      "Epoch [29/45], Step [3200/3663], Loss: 0.2075\n",
      "Epoch [29/45], Step [3300/3663], Loss: 0.2131\n",
      "Epoch [29/45], Step [3400/3663], Loss: 0.2241\n",
      "Epoch [29/45], Step [3500/3663], Loss: 0.2140\n",
      "Epoch [29/45], Step [3600/3663], Loss: 0.2180\n",
      "Loss of Epoch 29: 0.1981169454221664\n",
      "Epoch 30 began!\n",
      "Epoch [30/45], Step [100/3663], Loss: 0.1657\n",
      "Epoch [30/45], Step [200/3663], Loss: 0.1524\n",
      "Epoch [30/45], Step [300/3663], Loss: 0.1438\n",
      "Epoch [30/45], Step [400/3663], Loss: 0.1748\n",
      "Epoch [30/45], Step [500/3663], Loss: 0.1737\n",
      "Epoch [30/45], Step [600/3663], Loss: 0.1888\n",
      "Epoch [30/45], Step [700/3663], Loss: 0.1657\n",
      "Epoch [30/45], Step [800/3663], Loss: 0.1707\n",
      "Epoch [30/45], Step [900/3663], Loss: 0.2090\n",
      "Epoch [30/45], Step [1000/3663], Loss: 0.1571\n",
      "Epoch [30/45], Step [1100/3663], Loss: 0.1940\n",
      "Epoch [30/45], Step [1200/3663], Loss: 0.1797\n",
      "Epoch [30/45], Step [1300/3663], Loss: 0.2005\n",
      "Epoch [30/45], Step [1400/3663], Loss: 0.1576\n",
      "Epoch [30/45], Step [1500/3663], Loss: 0.1506\n",
      "Epoch [30/45], Step [1600/3663], Loss: 0.2266\n",
      "Epoch [30/45], Step [1700/3663], Loss: 0.2258\n",
      "Epoch [30/45], Step [1800/3663], Loss: 0.2255\n",
      "Epoch [30/45], Step [1900/3663], Loss: 0.1593\n",
      "Epoch [30/45], Step [2000/3663], Loss: 0.2123\n",
      "Epoch [30/45], Step [2100/3663], Loss: 0.2421\n",
      "Epoch [30/45], Step [2200/3663], Loss: 0.1937\n",
      "Epoch [30/45], Step [2300/3663], Loss: 0.1914\n",
      "Epoch [30/45], Step [2400/3663], Loss: 0.1934\n",
      "Epoch [30/45], Step [2500/3663], Loss: 0.1807\n",
      "Epoch [30/45], Step [2600/3663], Loss: 0.2223\n",
      "Epoch [30/45], Step [2700/3663], Loss: 0.1831\n",
      "Epoch [30/45], Step [2800/3663], Loss: 0.2298\n",
      "Epoch [30/45], Step [2900/3663], Loss: 0.2187\n",
      "Epoch [30/45], Step [3000/3663], Loss: 0.2077\n",
      "Epoch [30/45], Step [3100/3663], Loss: 0.2641\n",
      "Epoch [30/45], Step [3200/3663], Loss: 0.1925\n",
      "Epoch [30/45], Step [3300/3663], Loss: 0.1839\n",
      "Epoch [30/45], Step [3400/3663], Loss: 0.2120\n",
      "Epoch [30/45], Step [3500/3663], Loss: 0.2052\n",
      "Epoch [30/45], Step [3600/3663], Loss: 0.2124\n",
      "Loss of Epoch 30: 0.19434787475929471\n",
      "Epoch 31 began!\n",
      "Epoch [31/45], Step [100/3663], Loss: 0.1814\n",
      "Epoch [31/45], Step [200/3663], Loss: 0.1428\n",
      "Epoch [31/45], Step [300/3663], Loss: 0.1694\n",
      "Epoch [31/45], Step [400/3663], Loss: 0.1802\n",
      "Epoch [31/45], Step [500/3663], Loss: 0.1636\n",
      "Epoch [31/45], Step [600/3663], Loss: 0.1598\n",
      "Epoch [31/45], Step [700/3663], Loss: 0.1651\n",
      "Epoch [31/45], Step [800/3663], Loss: 0.1752\n",
      "Epoch [31/45], Step [900/3663], Loss: 0.1678\n",
      "Epoch [31/45], Step [1000/3663], Loss: 0.1820\n",
      "Epoch [31/45], Step [1100/3663], Loss: 0.1753\n",
      "Epoch [31/45], Step [1200/3663], Loss: 0.1946\n",
      "Epoch [31/45], Step [1300/3663], Loss: 0.1843\n",
      "Epoch [31/45], Step [1400/3663], Loss: 0.1931\n",
      "Epoch [31/45], Step [1500/3663], Loss: 0.2005\n",
      "Epoch [31/45], Step [1600/3663], Loss: 0.2006\n",
      "Epoch [31/45], Step [1700/3663], Loss: 0.1873\n",
      "Epoch [31/45], Step [1800/3663], Loss: 0.2070\n",
      "Epoch [31/45], Step [1900/3663], Loss: 0.1935\n",
      "Epoch [31/45], Step [2000/3663], Loss: 0.1663\n",
      "Epoch [31/45], Step [2100/3663], Loss: 0.1822\n",
      "Epoch [31/45], Step [2200/3663], Loss: 0.1940\n",
      "Epoch [31/45], Step [2300/3663], Loss: 0.1822\n",
      "Epoch [31/45], Step [2400/3663], Loss: 0.2133\n",
      "Epoch [31/45], Step [2500/3663], Loss: 0.1802\n",
      "Epoch [31/45], Step [2600/3663], Loss: 0.2148\n",
      "Epoch [31/45], Step [2700/3663], Loss: 0.2330\n",
      "Epoch [31/45], Step [2800/3663], Loss: 0.1900\n",
      "Epoch [31/45], Step [2900/3663], Loss: 0.1759\n",
      "Epoch [31/45], Step [3000/3663], Loss: 0.2407\n",
      "Epoch [31/45], Step [3100/3663], Loss: 0.2092\n",
      "Epoch [31/45], Step [3200/3663], Loss: 0.2059\n",
      "Epoch [31/45], Step [3300/3663], Loss: 0.2101\n",
      "Epoch [31/45], Step [3400/3663], Loss: 0.2201\n",
      "Epoch [31/45], Step [3500/3663], Loss: 0.1970\n",
      "Epoch [31/45], Step [3600/3663], Loss: 0.2496\n",
      "Loss of Epoch 31: 0.19206445944646333\n",
      "Epoch 32 began!\n",
      "Epoch [32/45], Step [100/3663], Loss: 0.1677\n",
      "Epoch [32/45], Step [200/3663], Loss: 0.2149\n",
      "Epoch [32/45], Step [300/3663], Loss: 0.2090\n",
      "Epoch [32/45], Step [400/3663], Loss: 0.1906\n",
      "Epoch [32/45], Step [500/3663], Loss: 0.2175\n",
      "Epoch [32/45], Step [600/3663], Loss: 0.1583\n",
      "Epoch [32/45], Step [700/3663], Loss: 0.1645\n",
      "Epoch [32/45], Step [800/3663], Loss: 0.1804\n",
      "Epoch [32/45], Step [900/3663], Loss: 0.1723\n",
      "Epoch [32/45], Step [1000/3663], Loss: 0.1792\n",
      "Epoch [32/45], Step [1100/3663], Loss: 0.1712\n",
      "Epoch [32/45], Step [1200/3663], Loss: 0.2009\n",
      "Epoch [32/45], Step [1300/3663], Loss: 0.1682\n",
      "Epoch [32/45], Step [1400/3663], Loss: 0.1703\n",
      "Epoch [32/45], Step [1500/3663], Loss: 0.1937\n",
      "Epoch [32/45], Step [1600/3663], Loss: 0.1687\n",
      "Epoch [32/45], Step [1700/3663], Loss: 0.1972\n",
      "Epoch [32/45], Step [1800/3663], Loss: 0.2273\n",
      "Epoch [32/45], Step [1900/3663], Loss: 0.2038\n",
      "Epoch [32/45], Step [2000/3663], Loss: 0.1732\n",
      "Epoch [32/45], Step [2100/3663], Loss: 0.2052\n",
      "Epoch [32/45], Step [2200/3663], Loss: 0.2087\n",
      "Epoch [32/45], Step [2300/3663], Loss: 0.1434\n",
      "Epoch [32/45], Step [2400/3663], Loss: 0.1804\n",
      "Epoch [32/45], Step [2500/3663], Loss: 0.1784\n",
      "Epoch [32/45], Step [2600/3663], Loss: 0.2010\n",
      "Epoch [32/45], Step [2700/3663], Loss: 0.2317\n",
      "Epoch [32/45], Step [2800/3663], Loss: 0.2091\n",
      "Epoch [32/45], Step [2900/3663], Loss: 0.1933\n",
      "Epoch [32/45], Step [3000/3663], Loss: 0.1466\n",
      "Epoch [32/45], Step [3100/3663], Loss: 0.2069\n",
      "Epoch [32/45], Step [3200/3663], Loss: 0.2113\n",
      "Epoch [32/45], Step [3300/3663], Loss: 0.1868\n",
      "Epoch [32/45], Step [3400/3663], Loss: 0.2144\n",
      "Epoch [32/45], Step [3500/3663], Loss: 0.1959\n",
      "Epoch [32/45], Step [3600/3663], Loss: 0.1933\n",
      "Loss of Epoch 32: 0.18922864330472128\n",
      "Epoch 33 began!\n",
      "Epoch [33/45], Step [100/3663], Loss: 0.1558\n",
      "Epoch [33/45], Step [200/3663], Loss: 0.1684\n",
      "Epoch [33/45], Step [300/3663], Loss: 0.1935\n",
      "Epoch [33/45], Step [400/3663], Loss: 0.1691\n",
      "Epoch [33/45], Step [500/3663], Loss: 0.1789\n",
      "Epoch [33/45], Step [600/3663], Loss: 0.1618\n",
      "Epoch [33/45], Step [700/3663], Loss: 0.1728\n",
      "Epoch [33/45], Step [800/3663], Loss: 0.1654\n",
      "Epoch [33/45], Step [900/3663], Loss: 0.1672\n",
      "Epoch [33/45], Step [1000/3663], Loss: 0.1942\n",
      "Epoch [33/45], Step [1100/3663], Loss: 0.1553\n",
      "Epoch [33/45], Step [1200/3663], Loss: 0.1699\n",
      "Epoch [33/45], Step [1300/3663], Loss: 0.1845\n",
      "Epoch [33/45], Step [1400/3663], Loss: 0.1772\n",
      "Epoch [33/45], Step [1500/3663], Loss: 0.1780\n",
      "Epoch [33/45], Step [1600/3663], Loss: 0.2000\n",
      "Epoch [33/45], Step [1700/3663], Loss: 0.1936\n",
      "Epoch [33/45], Step [1800/3663], Loss: 0.2046\n",
      "Epoch [33/45], Step [1900/3663], Loss: 0.1687\n",
      "Epoch [33/45], Step [2000/3663], Loss: 0.1875\n",
      "Epoch [33/45], Step [2100/3663], Loss: 0.1946\n",
      "Epoch [33/45], Step [2200/3663], Loss: 0.1768\n",
      "Epoch [33/45], Step [2300/3663], Loss: 0.1800\n",
      "Epoch [33/45], Step [2400/3663], Loss: 0.1759\n",
      "Epoch [33/45], Step [2500/3663], Loss: 0.1843\n",
      "Epoch [33/45], Step [2600/3663], Loss: 0.2295\n",
      "Epoch [33/45], Step [2700/3663], Loss: 0.1978\n",
      "Epoch [33/45], Step [2800/3663], Loss: 0.2169\n",
      "Epoch [33/45], Step [2900/3663], Loss: 0.2073\n",
      "Epoch [33/45], Step [3000/3663], Loss: 0.1938\n",
      "Epoch [33/45], Step [3100/3663], Loss: 0.2336\n",
      "Epoch [33/45], Step [3200/3663], Loss: 0.2545\n",
      "Epoch [33/45], Step [3300/3663], Loss: 0.1981\n",
      "Epoch [33/45], Step [3400/3663], Loss: 0.1969\n",
      "Epoch [33/45], Step [3500/3663], Loss: 0.2194\n",
      "Epoch [33/45], Step [3600/3663], Loss: 0.1932\n",
      "Loss of Epoch 33: 0.18884505497677645\n",
      "Epoch 34 began!\n",
      "Epoch [34/45], Step [100/3663], Loss: 0.1604\n",
      "Epoch [34/45], Step [200/3663], Loss: 0.2017\n",
      "Epoch [34/45], Step [300/3663], Loss: 0.1560\n",
      "Epoch [34/45], Step [400/3663], Loss: 0.1773\n",
      "Epoch [34/45], Step [500/3663], Loss: 0.1877\n",
      "Epoch [34/45], Step [600/3663], Loss: 0.1788\n",
      "Epoch [34/45], Step [700/3663], Loss: 0.1756\n",
      "Epoch [34/45], Step [800/3663], Loss: 0.1712\n",
      "Epoch [34/45], Step [900/3663], Loss: 0.1828\n",
      "Epoch [34/45], Step [1000/3663], Loss: 0.1633\n",
      "Epoch [34/45], Step [1100/3663], Loss: 0.1848\n",
      "Epoch [34/45], Step [1200/3663], Loss: 0.1689\n",
      "Epoch [34/45], Step [1300/3663], Loss: 0.1753\n",
      "Epoch [34/45], Step [1400/3663], Loss: 0.2347\n",
      "Epoch [34/45], Step [1500/3663], Loss: 0.1703\n",
      "Epoch [34/45], Step [1600/3663], Loss: 0.1931\n",
      "Epoch [34/45], Step [1700/3663], Loss: 0.1840\n",
      "Epoch [34/45], Step [1800/3663], Loss: 0.1414\n",
      "Epoch [34/45], Step [1900/3663], Loss: 0.1961\n",
      "Epoch [34/45], Step [2000/3663], Loss: 0.2121\n",
      "Epoch [34/45], Step [2100/3663], Loss: 0.1896\n",
      "Epoch [34/45], Step [2200/3663], Loss: 0.1750\n",
      "Epoch [34/45], Step [2300/3663], Loss: 0.2115\n",
      "Epoch [34/45], Step [2400/3663], Loss: 0.1929\n",
      "Epoch [34/45], Step [2500/3663], Loss: 0.1868\n",
      "Epoch [34/45], Step [2600/3663], Loss: 0.1872\n",
      "Epoch [34/45], Step [2700/3663], Loss: 0.1758\n",
      "Epoch [34/45], Step [2800/3663], Loss: 0.1710\n",
      "Epoch [34/45], Step [2900/3663], Loss: 0.1866\n",
      "Epoch [34/45], Step [3000/3663], Loss: 0.1971\n",
      "Epoch [34/45], Step [3100/3663], Loss: 0.2123\n",
      "Epoch [34/45], Step [3200/3663], Loss: 0.1910\n",
      "Epoch [34/45], Step [3300/3663], Loss: 0.1841\n",
      "Epoch [34/45], Step [3400/3663], Loss: 0.2064\n",
      "Epoch [34/45], Step [3500/3663], Loss: 0.1584\n",
      "Epoch [34/45], Step [3600/3663], Loss: 0.2208\n",
      "Loss of Epoch 34: 0.1852619201713693\n",
      "Epoch 35 began!\n",
      "Epoch [35/45], Step [100/3663], Loss: 0.1713\n",
      "Epoch [35/45], Step [200/3663], Loss: 0.1615\n",
      "Epoch [35/45], Step [300/3663], Loss: 0.1606\n",
      "Epoch [35/45], Step [400/3663], Loss: 0.1588\n",
      "Epoch [35/45], Step [500/3663], Loss: 0.1482\n",
      "Epoch [35/45], Step [600/3663], Loss: 0.1956\n",
      "Epoch [35/45], Step [700/3663], Loss: 0.1573\n",
      "Epoch [35/45], Step [800/3663], Loss: 0.1844\n",
      "Epoch [35/45], Step [900/3663], Loss: 0.1692\n",
      "Epoch [35/45], Step [1000/3663], Loss: 0.1606\n",
      "Epoch [35/45], Step [1100/3663], Loss: 0.1756\n",
      "Epoch [35/45], Step [1200/3663], Loss: 0.1929\n",
      "Epoch [35/45], Step [1300/3663], Loss: 0.1649\n",
      "Epoch [35/45], Step [1400/3663], Loss: 0.2125\n",
      "Epoch [35/45], Step [1500/3663], Loss: 0.2078\n",
      "Epoch [35/45], Step [1600/3663], Loss: 0.1878\n",
      "Epoch [35/45], Step [1700/3663], Loss: 0.1888\n",
      "Epoch [35/45], Step [1800/3663], Loss: 0.1590\n",
      "Epoch [35/45], Step [1900/3663], Loss: 0.1884\n",
      "Epoch [35/45], Step [2000/3663], Loss: 0.2162\n",
      "Epoch [35/45], Step [2100/3663], Loss: 0.1764\n",
      "Epoch [35/45], Step [2200/3663], Loss: 0.2193\n",
      "Epoch [35/45], Step [2300/3663], Loss: 0.1966\n",
      "Epoch [35/45], Step [2400/3663], Loss: 0.1702\n",
      "Epoch [35/45], Step [2500/3663], Loss: 0.1539\n",
      "Epoch [35/45], Step [2600/3663], Loss: 0.2025\n",
      "Epoch [35/45], Step [2700/3663], Loss: 0.1872\n",
      "Epoch [35/45], Step [2800/3663], Loss: 0.1988\n",
      "Epoch [35/45], Step [2900/3663], Loss: 0.2166\n",
      "Epoch [35/45], Step [3000/3663], Loss: 0.1931\n",
      "Epoch [35/45], Step [3100/3663], Loss: 0.1817\n",
      "Epoch [35/45], Step [3200/3663], Loss: 0.2243\n",
      "Epoch [35/45], Step [3300/3663], Loss: 0.1860\n",
      "Epoch [35/45], Step [3400/3663], Loss: 0.2300\n",
      "Epoch [35/45], Step [3500/3663], Loss: 0.1818\n",
      "Epoch [35/45], Step [3600/3663], Loss: 0.1807\n",
      "Loss of Epoch 35: 0.18550719399067594\n",
      "Epoch 36 began!\n",
      "Epoch [36/45], Step [100/3663], Loss: 0.1611\n",
      "Epoch [36/45], Step [200/3663], Loss: 0.1628\n",
      "Epoch [36/45], Step [300/3663], Loss: 0.1537\n",
      "Epoch [36/45], Step [400/3663], Loss: 0.1548\n",
      "Epoch [36/45], Step [500/3663], Loss: 0.1711\n",
      "Epoch [36/45], Step [600/3663], Loss: 0.1580\n",
      "Epoch [36/45], Step [700/3663], Loss: 0.1857\n",
      "Epoch [36/45], Step [800/3663], Loss: 0.1613\n",
      "Epoch [36/45], Step [900/3663], Loss: 0.1747\n",
      "Epoch [36/45], Step [1000/3663], Loss: 0.1586\n",
      "Epoch [36/45], Step [1100/3663], Loss: 0.1794\n",
      "Epoch [36/45], Step [1200/3663], Loss: 0.1757\n",
      "Epoch [36/45], Step [1300/3663], Loss: 0.1877\n",
      "Epoch [36/45], Step [1400/3663], Loss: 0.1573\n",
      "Epoch [36/45], Step [1500/3663], Loss: 0.1988\n",
      "Epoch [36/45], Step [1600/3663], Loss: 0.1847\n",
      "Epoch [36/45], Step [1700/3663], Loss: 0.1924\n",
      "Epoch [36/45], Step [1800/3663], Loss: 0.1849\n",
      "Epoch [36/45], Step [1900/3663], Loss: 0.2232\n",
      "Epoch [36/45], Step [2000/3663], Loss: 0.1725\n",
      "Epoch [36/45], Step [2100/3663], Loss: 0.1989\n",
      "Epoch [36/45], Step [2200/3663], Loss: 0.1997\n",
      "Epoch [36/45], Step [2300/3663], Loss: 0.1992\n",
      "Epoch [36/45], Step [2400/3663], Loss: 0.1801\n",
      "Epoch [36/45], Step [2500/3663], Loss: 0.1893\n",
      "Epoch [36/45], Step [2600/3663], Loss: 0.2621\n",
      "Epoch [36/45], Step [2700/3663], Loss: 0.1696\n",
      "Epoch [36/45], Step [2800/3663], Loss: 0.2110\n",
      "Epoch [36/45], Step [2900/3663], Loss: 0.1432\n",
      "Epoch [36/45], Step [3000/3663], Loss: 0.2006\n",
      "Epoch [36/45], Step [3100/3663], Loss: 0.1951\n",
      "Epoch [36/45], Step [3200/3663], Loss: 0.2247\n",
      "Epoch [36/45], Step [3300/3663], Loss: 0.1976\n",
      "Epoch [36/45], Step [3400/3663], Loss: 0.1884\n",
      "Epoch [36/45], Step [3500/3663], Loss: 0.2024\n",
      "Epoch [36/45], Step [3600/3663], Loss: 0.1512\n",
      "Loss of Epoch 36: 0.18349924026893738\n",
      "Epoch 37 began!\n",
      "Epoch [37/45], Step [100/3663], Loss: 0.1422\n",
      "Epoch [37/45], Step [200/3663], Loss: 0.1605\n",
      "Epoch [37/45], Step [300/3663], Loss: 0.2058\n",
      "Epoch [37/45], Step [400/3663], Loss: 0.1421\n",
      "Epoch [37/45], Step [500/3663], Loss: 0.1234\n",
      "Epoch [37/45], Step [600/3663], Loss: 0.1595\n",
      "Epoch [37/45], Step [700/3663], Loss: 0.1849\n",
      "Epoch [37/45], Step [800/3663], Loss: 0.1778\n",
      "Epoch [37/45], Step [900/3663], Loss: 0.1718\n",
      "Epoch [37/45], Step [1000/3663], Loss: 0.1681\n",
      "Epoch [37/45], Step [1100/3663], Loss: 0.2247\n",
      "Epoch [37/45], Step [1200/3663], Loss: 0.1721\n",
      "Epoch [37/45], Step [1300/3663], Loss: 0.1856\n",
      "Epoch [37/45], Step [1400/3663], Loss: 0.1948\n",
      "Epoch [37/45], Step [1500/3663], Loss: 0.2057\n",
      "Epoch [37/45], Step [1600/3663], Loss: 0.1769\n",
      "Epoch [37/45], Step [1700/3663], Loss: 0.1635\n",
      "Epoch [37/45], Step [1800/3663], Loss: 0.1937\n",
      "Epoch [37/45], Step [1900/3663], Loss: 0.1555\n",
      "Epoch [37/45], Step [2000/3663], Loss: 0.1653\n",
      "Epoch [37/45], Step [2100/3663], Loss: 0.1746\n",
      "Epoch [37/45], Step [2200/3663], Loss: 0.1745\n",
      "Epoch [37/45], Step [2300/3663], Loss: 0.1439\n",
      "Epoch [37/45], Step [2400/3663], Loss: 0.1922\n",
      "Epoch [37/45], Step [2500/3663], Loss: 0.1921\n",
      "Epoch [37/45], Step [2600/3663], Loss: 0.2010\n",
      "Epoch [37/45], Step [2700/3663], Loss: 0.1997\n",
      "Epoch [37/45], Step [2800/3663], Loss: 0.1841\n",
      "Epoch [37/45], Step [2900/3663], Loss: 0.1967\n",
      "Epoch [37/45], Step [3000/3663], Loss: 0.1984\n",
      "Epoch [37/45], Step [3100/3663], Loss: 0.2289\n",
      "Epoch [37/45], Step [3200/3663], Loss: 0.1710\n",
      "Epoch [37/45], Step [3300/3663], Loss: 0.1728\n",
      "Epoch [37/45], Step [3400/3663], Loss: 0.1947\n",
      "Epoch [37/45], Step [3500/3663], Loss: 0.1940\n",
      "Epoch [37/45], Step [3600/3663], Loss: 0.1825\n",
      "Loss of Epoch 37: 0.1809814950052271\n",
      "Epoch 38 began!\n",
      "Epoch [38/45], Step [100/3663], Loss: 0.1257\n",
      "Epoch [38/45], Step [200/3663], Loss: 0.1836\n",
      "Epoch [38/45], Step [300/3663], Loss: 0.1606\n",
      "Epoch [38/45], Step [400/3663], Loss: 0.1459\n",
      "Epoch [38/45], Step [500/3663], Loss: 0.1566\n",
      "Epoch [38/45], Step [600/3663], Loss: 0.1421\n",
      "Epoch [38/45], Step [700/3663], Loss: 0.1575\n",
      "Epoch [38/45], Step [800/3663], Loss: 0.1438\n",
      "Epoch [38/45], Step [900/3663], Loss: 0.1401\n",
      "Epoch [38/45], Step [1000/3663], Loss: 0.1779\n",
      "Epoch [38/45], Step [1100/3663], Loss: 0.1487\n",
      "Epoch [38/45], Step [1200/3663], Loss: 0.1908\n",
      "Epoch [38/45], Step [1300/3663], Loss: 0.1592\n",
      "Epoch [38/45], Step [1400/3663], Loss: 0.2052\n",
      "Epoch [38/45], Step [1500/3663], Loss: 0.1493\n",
      "Epoch [38/45], Step [1600/3663], Loss: 0.1824\n",
      "Epoch [38/45], Step [1700/3663], Loss: 0.1631\n",
      "Epoch [38/45], Step [1800/3663], Loss: 0.1636\n",
      "Epoch [38/45], Step [1900/3663], Loss: 0.2071\n",
      "Epoch [38/45], Step [2000/3663], Loss: 0.1764\n",
      "Epoch [38/45], Step [2100/3663], Loss: 0.1956\n",
      "Epoch [38/45], Step [2200/3663], Loss: 0.1810\n",
      "Epoch [38/45], Step [2300/3663], Loss: 0.1838\n",
      "Epoch [38/45], Step [2400/3663], Loss: 0.1946\n",
      "Epoch [38/45], Step [2500/3663], Loss: 0.1878\n",
      "Epoch [38/45], Step [2600/3663], Loss: 0.2258\n",
      "Epoch [38/45], Step [2700/3663], Loss: 0.2270\n",
      "Epoch [38/45], Step [2800/3663], Loss: 0.1957\n",
      "Epoch [38/45], Step [2900/3663], Loss: 0.1983\n",
      "Epoch [38/45], Step [3000/3663], Loss: 0.2363\n",
      "Epoch [38/45], Step [3100/3663], Loss: 0.1864\n",
      "Epoch [38/45], Step [3200/3663], Loss: 0.1809\n",
      "Epoch [38/45], Step [3300/3663], Loss: 0.1958\n",
      "Epoch [38/45], Step [3400/3663], Loss: 0.1693\n",
      "Epoch [38/45], Step [3500/3663], Loss: 0.1996\n",
      "Epoch [38/45], Step [3600/3663], Loss: 0.1812\n",
      "Loss of Epoch 38: 0.17896731273508742\n",
      "Epoch 39 began!\n",
      "Epoch [39/45], Step [100/3663], Loss: 0.1388\n",
      "Epoch [39/45], Step [200/3663], Loss: 0.1937\n",
      "Epoch [39/45], Step [300/3663], Loss: 0.1615\n",
      "Epoch [39/45], Step [400/3663], Loss: 0.1556\n",
      "Epoch [39/45], Step [500/3663], Loss: 0.1359\n",
      "Epoch [39/45], Step [600/3663], Loss: 0.1604\n",
      "Epoch [39/45], Step [700/3663], Loss: 0.1635\n",
      "Epoch [39/45], Step [800/3663], Loss: 0.1500\n",
      "Epoch [39/45], Step [900/3663], Loss: 0.1641\n",
      "Epoch [39/45], Step [1000/3663], Loss: 0.1776\n",
      "Epoch [39/45], Step [1100/3663], Loss: 0.2080\n",
      "Epoch [39/45], Step [1200/3663], Loss: 0.1906\n",
      "Epoch [39/45], Step [1300/3663], Loss: 0.1917\n",
      "Epoch [39/45], Step [1400/3663], Loss: 0.1755\n",
      "Epoch [39/45], Step [1500/3663], Loss: 0.1911\n",
      "Epoch [39/45], Step [1600/3663], Loss: 0.1907\n",
      "Epoch [39/45], Step [1700/3663], Loss: 0.1669\n",
      "Epoch [39/45], Step [1800/3663], Loss: 0.1663\n",
      "Epoch [39/45], Step [1900/3663], Loss: 0.1530\n",
      "Epoch [39/45], Step [2000/3663], Loss: 0.1864\n",
      "Epoch [39/45], Step [2100/3663], Loss: 0.2010\n",
      "Epoch [39/45], Step [2200/3663], Loss: 0.1770\n",
      "Epoch [39/45], Step [2300/3663], Loss: 0.1600\n",
      "Epoch [39/45], Step [2400/3663], Loss: 0.1955\n",
      "Epoch [39/45], Step [2500/3663], Loss: 0.2040\n",
      "Epoch [39/45], Step [2600/3663], Loss: 0.2114\n",
      "Epoch [39/45], Step [2700/3663], Loss: 0.1610\n",
      "Epoch [39/45], Step [2800/3663], Loss: 0.1974\n",
      "Epoch [39/45], Step [2900/3663], Loss: 0.1726\n",
      "Epoch [39/45], Step [3000/3663], Loss: 0.2072\n",
      "Epoch [39/45], Step [3100/3663], Loss: 0.2068\n",
      "Epoch [39/45], Step [3200/3663], Loss: 0.1898\n",
      "Epoch [39/45], Step [3300/3663], Loss: 0.1663\n",
      "Epoch [39/45], Step [3400/3663], Loss: 0.1685\n",
      "Epoch [39/45], Step [3500/3663], Loss: 0.1726\n",
      "Epoch [39/45], Step [3600/3663], Loss: 0.1952\n",
      "Loss of Epoch 39: 0.17798493616158198\n",
      "Epoch 40 began!\n",
      "Epoch [40/45], Step [100/3663], Loss: 0.1500\n",
      "Epoch [40/45], Step [200/3663], Loss: 0.1833\n",
      "Epoch [40/45], Step [300/3663], Loss: 0.1351\n",
      "Epoch [40/45], Step [400/3663], Loss: 0.1542\n",
      "Epoch [40/45], Step [500/3663], Loss: 0.1725\n",
      "Epoch [40/45], Step [600/3663], Loss: 0.1354\n",
      "Epoch [40/45], Step [700/3663], Loss: 0.1630\n",
      "Epoch [40/45], Step [800/3663], Loss: 0.1572\n",
      "Epoch [40/45], Step [900/3663], Loss: 0.1791\n",
      "Epoch [40/45], Step [1000/3663], Loss: 0.1713\n",
      "Epoch [40/45], Step [1100/3663], Loss: 0.1651\n",
      "Epoch [40/45], Step [1200/3663], Loss: 0.1865\n",
      "Epoch [40/45], Step [1300/3663], Loss: 0.1925\n",
      "Epoch [40/45], Step [1400/3663], Loss: 0.1818\n",
      "Epoch [40/45], Step [1500/3663], Loss: 0.1751\n",
      "Epoch [40/45], Step [1600/3663], Loss: 0.1957\n",
      "Epoch [40/45], Step [1700/3663], Loss: 0.1472\n",
      "Epoch [40/45], Step [1800/3663], Loss: 0.1869\n",
      "Epoch [40/45], Step [1900/3663], Loss: 0.1729\n",
      "Epoch [40/45], Step [2000/3663], Loss: 0.1364\n",
      "Epoch [40/45], Step [2100/3663], Loss: 0.2007\n",
      "Epoch [40/45], Step [2200/3663], Loss: 0.1774\n",
      "Epoch [40/45], Step [2300/3663], Loss: 0.1842\n",
      "Epoch [40/45], Step [2400/3663], Loss: 0.1682\n",
      "Epoch [40/45], Step [2500/3663], Loss: 0.1845\n",
      "Epoch [40/45], Step [2600/3663], Loss: 0.1636\n",
      "Epoch [40/45], Step [2700/3663], Loss: 0.1790\n",
      "Epoch [40/45], Step [2800/3663], Loss: 0.1828\n",
      "Epoch [40/45], Step [2900/3663], Loss: 0.1843\n",
      "Epoch [40/45], Step [3000/3663], Loss: 0.1709\n",
      "Epoch [40/45], Step [3100/3663], Loss: 0.1952\n",
      "Epoch [40/45], Step [3200/3663], Loss: 0.1943\n",
      "Epoch [40/45], Step [3300/3663], Loss: 0.1812\n",
      "Epoch [40/45], Step [3400/3663], Loss: 0.1660\n",
      "Epoch [40/45], Step [3500/3663], Loss: 0.2142\n",
      "Epoch [40/45], Step [3600/3663], Loss: 0.1833\n",
      "Loss of Epoch 40: 0.17504073712848647\n",
      "Epoch 41 began!\n",
      "Epoch [41/45], Step [100/3663], Loss: 0.1213\n",
      "Epoch [41/45], Step [200/3663], Loss: 0.1480\n",
      "Epoch [41/45], Step [300/3663], Loss: 0.1452\n",
      "Epoch [41/45], Step [400/3663], Loss: 0.1458\n",
      "Epoch [41/45], Step [500/3663], Loss: 0.1581\n",
      "Epoch [41/45], Step [600/3663], Loss: 0.1351\n",
      "Epoch [41/45], Step [700/3663], Loss: 0.1949\n",
      "Epoch [41/45], Step [800/3663], Loss: 0.2163\n",
      "Epoch [41/45], Step [900/3663], Loss: 0.1850\n",
      "Epoch [41/45], Step [1000/3663], Loss: 0.2059\n",
      "Epoch [41/45], Step [1100/3663], Loss: 0.1589\n",
      "Epoch [41/45], Step [1200/3663], Loss: 0.1763\n",
      "Epoch [41/45], Step [1300/3663], Loss: 0.2016\n",
      "Epoch [41/45], Step [1400/3663], Loss: 0.1669\n",
      "Epoch [41/45], Step [1500/3663], Loss: 0.1701\n",
      "Epoch [41/45], Step [1600/3663], Loss: 0.1935\n",
      "Epoch [41/45], Step [1700/3663], Loss: 0.2483\n",
      "Epoch [41/45], Step [1800/3663], Loss: 0.1925\n",
      "Epoch [41/45], Step [1900/3663], Loss: 0.1587\n",
      "Epoch [41/45], Step [2000/3663], Loss: 0.1607\n",
      "Epoch [41/45], Step [2100/3663], Loss: 0.1723\n",
      "Epoch [41/45], Step [2200/3663], Loss: 0.1578\n",
      "Epoch [41/45], Step [2300/3663], Loss: 0.1924\n",
      "Epoch [41/45], Step [2400/3663], Loss: 0.1613\n",
      "Epoch [41/45], Step [2500/3663], Loss: 0.1734\n",
      "Epoch [41/45], Step [2600/3663], Loss: 0.1547\n",
      "Epoch [41/45], Step [2700/3663], Loss: 0.1852\n",
      "Epoch [41/45], Step [2800/3663], Loss: 0.1523\n",
      "Epoch [41/45], Step [2900/3663], Loss: 0.1977\n",
      "Epoch [41/45], Step [3000/3663], Loss: 0.1838\n",
      "Epoch [41/45], Step [3100/3663], Loss: 0.1540\n",
      "Epoch [41/45], Step [3200/3663], Loss: 0.2004\n",
      "Epoch [41/45], Step [3300/3663], Loss: 0.1916\n",
      "Epoch [41/45], Step [3400/3663], Loss: 0.2033\n",
      "Epoch [41/45], Step [3500/3663], Loss: 0.1489\n",
      "Epoch [41/45], Step [3600/3663], Loss: 0.1709\n",
      "Loss of Epoch 41: 0.1742556668691062\n",
      "Epoch 42 began!\n",
      "Epoch [42/45], Step [100/3663], Loss: 0.1447\n",
      "Epoch [42/45], Step [200/3663], Loss: 0.1512\n",
      "Epoch [42/45], Step [300/3663], Loss: 0.1536\n",
      "Epoch [42/45], Step [400/3663], Loss: 0.1370\n",
      "Epoch [42/45], Step [500/3663], Loss: 0.1286\n",
      "Epoch [42/45], Step [600/3663], Loss: 0.1523\n",
      "Epoch [42/45], Step [700/3663], Loss: 0.1254\n",
      "Epoch [42/45], Step [800/3663], Loss: 0.1773\n",
      "Epoch [42/45], Step [900/3663], Loss: 0.1793\n",
      "Epoch [42/45], Step [1000/3663], Loss: 0.1669\n",
      "Epoch [42/45], Step [1100/3663], Loss: 0.1391\n",
      "Epoch [42/45], Step [1200/3663], Loss: 0.1903\n",
      "Epoch [42/45], Step [1300/3663], Loss: 0.1778\n",
      "Epoch [42/45], Step [1400/3663], Loss: 0.1663\n",
      "Epoch [42/45], Step [1500/3663], Loss: 0.1596\n",
      "Epoch [42/45], Step [1600/3663], Loss: 0.2106\n",
      "Epoch [42/45], Step [1700/3663], Loss: 0.2309\n",
      "Epoch [42/45], Step [1800/3663], Loss: 0.2079\n",
      "Epoch [42/45], Step [1900/3663], Loss: 0.1600\n",
      "Epoch [42/45], Step [2000/3663], Loss: 0.1585\n",
      "Epoch [42/45], Step [2100/3663], Loss: 0.1788\n",
      "Epoch [42/45], Step [2200/3663], Loss: 0.1811\n",
      "Epoch [42/45], Step [2300/3663], Loss: 0.1787\n",
      "Epoch [42/45], Step [2400/3663], Loss: 0.2094\n",
      "Epoch [42/45], Step [2500/3663], Loss: 0.1892\n",
      "Epoch [42/45], Step [2600/3663], Loss: 0.1710\n",
      "Epoch [42/45], Step [2700/3663], Loss: 0.1827\n",
      "Epoch [42/45], Step [2800/3663], Loss: 0.1923\n",
      "Epoch [42/45], Step [2900/3663], Loss: 0.1654\n",
      "Epoch [42/45], Step [3000/3663], Loss: 0.1852\n",
      "Epoch [42/45], Step [3100/3663], Loss: 0.1504\n",
      "Epoch [42/45], Step [3200/3663], Loss: 0.2147\n",
      "Epoch [42/45], Step [3300/3663], Loss: 0.1664\n",
      "Epoch [42/45], Step [3400/3663], Loss: 0.1918\n",
      "Epoch [42/45], Step [3500/3663], Loss: 0.1829\n",
      "Epoch [42/45], Step [3600/3663], Loss: 0.1783\n",
      "Loss of Epoch 42: 0.17322624189153038\n",
      "Epoch 43 began!\n",
      "Epoch [43/45], Step [100/3663], Loss: 0.1310\n",
      "Epoch [43/45], Step [200/3663], Loss: 0.1226\n",
      "Epoch [43/45], Step [300/3663], Loss: 0.1526\n",
      "Epoch [43/45], Step [400/3663], Loss: 0.1594\n",
      "Epoch [43/45], Step [500/3663], Loss: 0.1553\n",
      "Epoch [43/45], Step [600/3663], Loss: 0.1670\n",
      "Epoch [43/45], Step [700/3663], Loss: 0.1256\n",
      "Epoch [43/45], Step [800/3663], Loss: 0.1595\n",
      "Epoch [43/45], Step [900/3663], Loss: 0.1664\n",
      "Epoch [43/45], Step [1000/3663], Loss: 0.1688\n",
      "Epoch [43/45], Step [1100/3663], Loss: 0.1850\n",
      "Epoch [43/45], Step [1200/3663], Loss: 0.1786\n",
      "Epoch [43/45], Step [1300/3663], Loss: 0.1808\n",
      "Epoch [43/45], Step [1400/3663], Loss: 0.1596\n",
      "Epoch [43/45], Step [1500/3663], Loss: 0.1394\n",
      "Epoch [43/45], Step [1600/3663], Loss: 0.1513\n",
      "Epoch [43/45], Step [1700/3663], Loss: 0.1612\n",
      "Epoch [43/45], Step [1800/3663], Loss: 0.1897\n",
      "Epoch [43/45], Step [1900/3663], Loss: 0.1456\n",
      "Epoch [43/45], Step [2000/3663], Loss: 0.2031\n",
      "Epoch [43/45], Step [2100/3663], Loss: 0.1722\n",
      "Epoch [43/45], Step [2200/3663], Loss: 0.1934\n",
      "Epoch [43/45], Step [2300/3663], Loss: 0.1501\n",
      "Epoch [43/45], Step [2400/3663], Loss: 0.1682\n",
      "Epoch [43/45], Step [2500/3663], Loss: 0.1826\n",
      "Epoch [43/45], Step [2600/3663], Loss: 0.1811\n",
      "Epoch [43/45], Step [2700/3663], Loss: 0.1790\n",
      "Epoch [43/45], Step [2800/3663], Loss: 0.1861\n",
      "Epoch [43/45], Step [2900/3663], Loss: 0.1855\n",
      "Epoch [43/45], Step [3000/3663], Loss: 0.1765\n",
      "Epoch [43/45], Step [3100/3663], Loss: 0.1941\n",
      "Epoch [43/45], Step [3200/3663], Loss: 0.1874\n",
      "Epoch [43/45], Step [3300/3663], Loss: 0.2096\n",
      "Epoch [43/45], Step [3400/3663], Loss: 0.2196\n",
      "Epoch [43/45], Step [3500/3663], Loss: 0.1865\n",
      "Epoch [43/45], Step [3600/3663], Loss: 0.2078\n",
      "Loss of Epoch 43: 0.17196520062336976\n",
      "Epoch 44 began!\n",
      "Epoch [44/45], Step [100/3663], Loss: 0.1709\n",
      "Epoch [44/45], Step [200/3663], Loss: 0.1632\n",
      "Epoch [44/45], Step [300/3663], Loss: 0.1499\n",
      "Epoch [44/45], Step [400/3663], Loss: 0.1391\n",
      "Epoch [44/45], Step [500/3663], Loss: 0.1598\n",
      "Epoch [44/45], Step [600/3663], Loss: 0.1513\n",
      "Epoch [44/45], Step [700/3663], Loss: 0.1310\n",
      "Epoch [44/45], Step [800/3663], Loss: 0.1798\n",
      "Epoch [44/45], Step [900/3663], Loss: 0.1548\n",
      "Epoch [44/45], Step [1000/3663], Loss: 0.1562\n",
      "Epoch [44/45], Step [1100/3663], Loss: 0.1573\n",
      "Epoch [44/45], Step [1200/3663], Loss: 0.1439\n",
      "Epoch [44/45], Step [1300/3663], Loss: 0.2027\n",
      "Epoch [44/45], Step [1400/3663], Loss: 0.1636\n",
      "Epoch [44/45], Step [1500/3663], Loss: 0.1659\n",
      "Epoch [44/45], Step [1600/3663], Loss: 0.1776\n",
      "Epoch [44/45], Step [1700/3663], Loss: 0.1693\n",
      "Epoch [44/45], Step [1800/3663], Loss: 0.1755\n",
      "Epoch [44/45], Step [1900/3663], Loss: 0.2108\n",
      "Epoch [44/45], Step [2000/3663], Loss: 0.1490\n",
      "Epoch [44/45], Step [2100/3663], Loss: 0.1980\n",
      "Epoch [44/45], Step [2200/3663], Loss: 0.1502\n",
      "Epoch [44/45], Step [2300/3663], Loss: 0.1865\n",
      "Epoch [44/45], Step [2400/3663], Loss: 0.1788\n",
      "Epoch [44/45], Step [2500/3663], Loss: 0.1868\n",
      "Epoch [44/45], Step [2600/3663], Loss: 0.1413\n",
      "Epoch [44/45], Step [2700/3663], Loss: 0.1825\n",
      "Epoch [44/45], Step [2800/3663], Loss: 0.1827\n",
      "Epoch [44/45], Step [2900/3663], Loss: 0.1525\n",
      "Epoch [44/45], Step [3000/3663], Loss: 0.1784\n",
      "Epoch [44/45], Step [3100/3663], Loss: 0.2261\n",
      "Epoch [44/45], Step [3200/3663], Loss: 0.1945\n",
      "Epoch [44/45], Step [3300/3663], Loss: 0.1751\n",
      "Epoch [44/45], Step [3400/3663], Loss: 0.1989\n",
      "Epoch [44/45], Step [3500/3663], Loss: 0.1784\n",
      "Epoch [44/45], Step [3600/3663], Loss: 0.1608\n",
      "Loss of Epoch 44: 0.1703702629823724\n",
      "Epoch 45 began!\n",
      "Epoch [45/45], Step [100/3663], Loss: 0.1437\n",
      "Epoch [45/45], Step [200/3663], Loss: 0.1758\n",
      "Epoch [45/45], Step [300/3663], Loss: 0.1841\n",
      "Epoch [45/45], Step [400/3663], Loss: 0.1697\n",
      "Epoch [45/45], Step [500/3663], Loss: 0.1367\n",
      "Epoch [45/45], Step [600/3663], Loss: 0.1190\n",
      "Epoch [45/45], Step [700/3663], Loss: 0.1710\n",
      "Epoch [45/45], Step [800/3663], Loss: 0.1594\n",
      "Epoch [45/45], Step [900/3663], Loss: 0.1668\n",
      "Epoch [45/45], Step [1000/3663], Loss: 0.1590\n",
      "Epoch [45/45], Step [1100/3663], Loss: 0.1553\n",
      "Epoch [45/45], Step [1200/3663], Loss: 0.1929\n",
      "Epoch [45/45], Step [1300/3663], Loss: 0.1626\n",
      "Epoch [45/45], Step [1400/3663], Loss: 0.1559\n",
      "Epoch [45/45], Step [1500/3663], Loss: 0.1621\n",
      "Epoch [45/45], Step [1600/3663], Loss: 0.1472\n",
      "Epoch [45/45], Step [1700/3663], Loss: 0.1536\n",
      "Epoch [45/45], Step [1800/3663], Loss: 0.1547\n",
      "Epoch [45/45], Step [1900/3663], Loss: 0.1360\n",
      "Epoch [45/45], Step [2000/3663], Loss: 0.1749\n",
      "Epoch [45/45], Step [2100/3663], Loss: 0.1984\n",
      "Epoch [45/45], Step [2200/3663], Loss: 0.1855\n",
      "Epoch [45/45], Step [2300/3663], Loss: 0.1827\n",
      "Epoch [45/45], Step [2400/3663], Loss: 0.1520\n",
      "Epoch [45/45], Step [2500/3663], Loss: 0.1909\n",
      "Epoch [45/45], Step [2600/3663], Loss: 0.2207\n",
      "Epoch [45/45], Step [2700/3663], Loss: 0.1684\n",
      "Epoch [45/45], Step [2800/3663], Loss: 0.1931\n",
      "Epoch [45/45], Step [2900/3663], Loss: 0.1770\n",
      "Epoch [45/45], Step [3000/3663], Loss: 0.1572\n",
      "Epoch [45/45], Step [3100/3663], Loss: 0.1967\n",
      "Epoch [45/45], Step [3200/3663], Loss: 0.1411\n",
      "Epoch [45/45], Step [3300/3663], Loss: 0.1784\n",
      "Epoch [45/45], Step [3400/3663], Loss: 0.2167\n",
      "Epoch [45/45], Step [3500/3663], Loss: 0.1576\n",
      "Epoch [45/45], Step [3600/3663], Loss: 0.2097\n",
      "Loss of Epoch 45: 0.16951547436351602\n",
      "\n",
      "Training Finished :)\n",
      "\n",
      "Trained and saved the CNN model with Softmax to OCR_CNN_model.pth\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the Softmax Loss plot to lossEpoch_graph.png\n"
     ]
    }
   ],
   "source": [
    "# Check if the model file exists\n",
    "if os.path.exists(OCR_model_path):\n",
    "\n",
    "    # Load the existing model\n",
    "    model = OCRModel(n_unique_labels)\n",
    "    model.load_state_dict(torch.load(OCR_model_path))\n",
    "    print(\"Loaded existing CNN model for ORC from\", OCR_model_path)\n",
    "    # Lets show the loss graph\n",
    "    image_Loss_Epoch = Image.open(lossEpoch_graph_path)\n",
    "    image_Loss_Epoch.show()\n",
    "\n",
    "else:\n",
    "\n",
    "    print(\"No molde saved found -> Beginning Training...\\n\")\n",
    "    print(f\"DONT FORGET:\\nTraining data has {len(train_data)} images and the batch size is {batch_size}.\\n\")\n",
    "    \n",
    "    # Define the optimzier with ADAM\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Define a list to store epoch losses\n",
    "    epoch_losses = []\n",
    "\n",
    "    # Training loop - Iterate over each epoch\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # Variables for traking\n",
    "        batch_counter = 0\n",
    "        epoch_loss = 0\n",
    "        epoch_loss_total = 0\n",
    "        print(f\"Epoch {epoch + 1} began!\")\n",
    "\n",
    "        # Iterate over each batch\n",
    "        for images, labels in dataloader_train:\n",
    "            # Lest reset the gradients (derivatives of the loss function)\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass: where we calculate the output of the neural network\n",
    "            prediction = model(images)\n",
    "            # Forward pass: where we calculate the loss of the model based on the predictions and the actual targets\n",
    "            loss = loss_criterion(prediction, labels)\n",
    "            # Backward Pass: where we compute the gradients of the loss with respect to each parameter\n",
    "            loss.backward()\n",
    "            # Finally we update the parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # Sum the loss of each step of the epoch\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_loss_total += loss.item()\n",
    "            if (batch_counter + 1) % 100 == 0: # Print every 100 batches\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_counter+1}/{total_steps}], Loss: {epoch_loss / 100:.4f}')\n",
    "                epoch_loss = 0\n",
    "    \n",
    "            # Increment batch_counter\n",
    "            batch_counter += 1\n",
    "\n",
    "        # Calculate average epoch loss\n",
    "        avg_epoch_loss = epoch_loss_total / len(dataloader_train)\n",
    "        print(f\"Loss of Epoch {epoch + 1}: {avg_epoch_loss}\")\n",
    "        epoch_losses.append(avg_epoch_loss)\n",
    "\n",
    "    print(\"\\nTraining Finished :)\")\n",
    "\n",
    "    # Save the trained model\n",
    "    torch.save(model.state_dict(), OCR_model_path)\n",
    "    print(\"\\nTrained and saved the CNN model with Softmax to\", OCR_model_path)\n",
    "\n",
    "    # Plotting the loss graph\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, num_epochs + 1), epoch_losses, label='Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss over Epochs')\n",
    "    plt.legend()\n",
    "    # Save the plot as an image\n",
    "    plt.savefig(lossEpoch_graph_path)\n",
    "    plt.show()\n",
    "    print(f\"Saved the Softmax Loss plot to {lossEpoch_graph_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad67db5-19f3-4cdb-b24b-1772d5df9b25",
   "metadata": {},
   "source": [
    "# Lets test the models we did\n",
    "###### Calculate accuracy of the model and then precission and recall per-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c4fe08d-2e95-4dd1-a226-1f88b1f8f11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics:\n",
      "Accuracy: 0.8775\n",
      "\n",
      "Precision per class:\n",
      "Class 0: 0.8660\n",
      "Class 1: 0.9121\n",
      "Class 2: 0.9189\n",
      "Class 3: 0.7938\n",
      "Class 4: 0.9069\n",
      "Class 5: 0.8839\n",
      "Class 6: 0.8455\n",
      "Class 7: 0.9113\n",
      "Class 8: 0.8543\n",
      "Class 9: 0.8067\n",
      "\n",
      "Recall per class:\n",
      "Class 0: 0.8710\n",
      "Class 1: 0.9196\n",
      "Class 2: 0.9062\n",
      "Class 3: 0.8685\n",
      "Class 4: 0.8914\n",
      "Class 5: 0.8721\n",
      "Class 6: 0.8467\n",
      "Class 7: 0.8603\n",
      "Class 8: 0.7735\n",
      "Class 9: 0.8451\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics import Accuracy, Precision, Recall\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Get the model on evaluation mode\n",
    "model.eval()\n",
    "\n",
    "metric_accuracy = Accuracy(task=\"multiclass\", num_classes=n_unique_labels)\n",
    "metric_precision = Precision(task=\"multiclass\", num_classes=n_unique_labels, average=None) \n",
    "metric_recall = Recall(task=\"multiclass\", num_classes=n_unique_labels, average=None)\n",
    "\n",
    "# Lets define the evaluation loop\n",
    "with torch.no_grad():\n",
    "    # Run though test images batches\n",
    "    for images, labels in dataloader_test:\n",
    "        # Get output from model\n",
    "        outputs = model(images)\n",
    "        # Predicted class label\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # Calculate the metrics\n",
    "        metric_accuracy(predictions, labels)\n",
    "        metric_precision(predictions, labels)\n",
    "        metric_recall(predictions, labels)\n",
    "\n",
    "# Compute the Metrics\n",
    "accuracy = metric_accuracy.compute()\n",
    "precision = metric_precision.compute()\n",
    "recall = metric_recall.compute()\n",
    "\n",
    "# Print the metrics\n",
    "print(\"\\nMetrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nPrecision per class:\")\n",
    "for i in range(n_unique_labels):\n",
    "    print(f\"Class {i}: {precision.tolist()[i]:.4f}\")\n",
    "\n",
    "print(\"\\nRecall per class:\")\n",
    "for i in range(n_unique_labels):\n",
    "    print(f\"Class {i}: {recall.tolist()[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f652fb61-24e6-4533-abea-e52f58a1e8d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
